\chapter{Πειραματική Αξιολόγηση και Αποτελέσματα}
\label{ch:experiments}

Στο κεφάλαιο αυτό παρουσιάζεται η πειραματική διαδικασία που ακολουθήθηκε
για την εκπαίδευση και τη συγκριτική αξιολόγηση διαφορετικών αρχιτεκτονικών
τμηματοποίησης σε \en{3D MRI}, καθώς και τα αντίστοιχα αποτελέσματα.

Η επιλογή των μοντέλων προέκυψε μέσα από συστηματική μελέτη της βιβλιογραφίας:
αρχικά εξετάστηκαν τα θεμελιώδη \en{U-shaped} δίκτυα (\en{U-Net})
\cite{ronneberger2015unet} και στη συνέχεια παραλλαγές/επεκτάσεις όπως το
\en{Attention U-Net} \cite{oktay2018attentionunet} και σύγχρονες \en{U-Net} μορφές
όπως το \en{DynUNet} \cite{isensee2021nnunet}.
Τέλος, αξιολογήθηκαν νεότερες προσεγγίσεις που μοντελοποιούν μακρινές
εξαρτήσεις, όπως τα \en{Transformer-based} μοντέλα
(\en{UNETR} \cite{hatamizadeh2022unetr},
\en{SwinUNETR} \cite{hatamizadeh2022swinunetr})
και \en{State Space-based} μοντέλα
(\en{SegMamba} \cite{xing2024segmamba}, βασισμένο στο \en{Mamba}
\cite{gu2023mamba}).

Κεντρικός στόχος είναι η \textbf{δίκαιη και αναπαραγώγιμη σύγκριση} των
αρχιτεκτονικών. Για τον λόγο αυτό υλοποιήθηκε ένα \textbf{ενιαίο πειραματικό
πλαίσιο} όπου όλες οι αρχιτεκτονικές εκπαιδεύονται με κοινή ροή
(\en{pipeline}) προεπεξεργασίας, δειγματοληψίας \en{patches}, εκπαίδευσης,
αξιολόγησης και καταγραφής μετρικών.
Στην πράξη, κάθε αρχιτεκτονική αντιστοιχεί σε ξεχωριστό \en{notebook},
όμως η δομή του κώδικα παραμένει σταθερή, με κύρια διαφοροποίηση την
αρχικοποίηση του μοντέλου και ελάχιστες αναγκαίες ρυθμίσεις συμβατότητας.

\section{Στόχοι αξιολόγησης και αρχές σύγκρισης}
\label{sec:exp_principles}

Στόχος της πειραματικής αξιολόγησης είναι να αποτυπωθεί με σαφήνεια η
σχετική συμπεριφορά διαφορετικών οικογενειών αρχιτεκτονικών σε τμηματοποίηση
πλακούντα σε \en{3D MRI}. Η σύγκριση σχεδιάστηκε ώστε να είναι δίκαιη, με
κοινό τρόπο αναφοράς αποτελεσμάτων και συνεπείς επιλογές αξιολόγησης, έτσι
ώστε οι παρατηρούμενες διαφορές να αποδίδονται κατά το δυνατόν στην
αρχιτεκτονική.

Η αναφορά βασίζεται κυρίως σε \en{Dice} και \en{IoU}, μετρικές που είναι
κατάλληλες για προβλήματα έντονης ανισορροπίας κλάσεων, ενώ η ερμηνεία δεν
στηρίζεται μόνο στη μέση τιμή αλλά συμπληρώνεται από ποιοτική επιθεώρηση και
σχολιασμό τυπικών αποτυχιών ανά περίπτωση (βλ. Κεφάλαιο~\ref{ch:discussion}).

\section{Υλοποίηση και λογισμικό}
\label{sec:exp_software}

Η υλοποίηση πραγματοποιήθηκε στο \en{PyTorch},
με χρήση του \en{MONAI} \cite{cardoso2022monai}, το οποίο παρέχει έτοιμες
αρχιτεκτονικές, μετασχηματισμούς (\en{transforms}), συναρτήσεις απώλειας,
και εργαλεία αξιολόγησης κατάλληλα για \en{3D} ιατρική τμηματοποίηση.

Όλες οι αρχιτεκτονικές (εκτός του \en{SegMamba}, που ενσωματώθηκε ως
εξωτερική υλοποίηση) χρησιμοποιούν κοινές συνιστώσες του \en{MONAI} για:
\begin{itemize}
  \item (α) ανάγνωση \en{NIfTI} δεδομένων,
  \item (β) προεπεξεργασία/επαύξηση, 
  \item (γ) \en{sliding-window inference},
  \item (δ) υπολογισμό μετρικών.
\end{itemize}

\section{Σύνολο δεδομένων και διαχωρισμός}
\label{sec:exp_data}

Το σύνολο δεδομένων περιλαμβάνει $N=137$ περιστατικά, με ένα ζεύγος αρχείων
\en{\texttt{.nii.gz}} ανά περίπτωση: έναν ογκομετρικό όγκο \en{MRI} και την
αντίστοιχη δυαδική μάσκα τμηματοποίησης πλακούντα.
Ως βασική μονάδα εκπαίδευσης και αξιολόγησης ορίζεται το \en{case}
(δηλαδή ολόκληρος ο \en{3D} όγκος), ώστε ο διαχωρισμός να γίνεται σε επίπεδο
ασθενή/περίπτωσης και να αποφεύγεται διαρροή πληροφορίας.

Ο διαχωρισμός σε σύνολα εκπαίδευσης και επικύρωσης πραγματοποιείται με
σταθερό \en{seed} ($121$) για λόγους αναπαραγωγιμότητας.
Στα πειράματα της παρούσας εργασίας χρησιμοποιήθηκε διαχωρισμός $80/20$,
που αντιστοιχεί περίπου σε $109$ περιστατικά εκπαίδευσης και $28$ επικύρωσης.

\section{Αρχιτεκτονικές και πειραματικά σενάρια}
\label{sec:exp_models}

Αξιολογήθηκαν οι παρακάτω αρχιτεκτονικές:
\begin{itemize}
  \item \en{U-Net} \cite{ronneberger2015unet}
  \item \en{Attention U-Net} \cite{oktay2018attentionunet}
  \item \en{DynUNet} \cite{isensee2021nnunet}
  \item \en{UNETR} \cite{hatamizadeh2022unetr}
  \item \en{SwinUNETR} \cite{hatamizadeh2022swinunetr}
  \item \en{SegResNet} \cite{myronenko2018segresnet}
  \item \en{SegMamba} \cite{xing2024segmamba}
\end{itemize}

\paragraph{Οικογένειες μοντέλων.}
Οι αρχιτεκτονικές που αξιολογούνται καλύπτουν κλασικές \en{CNN} προσεγγίσεις
(\en{U-Net} και παραλλαγές), νεότερες \en{Transformer}-βασισμένες δομές
(\en{UNETR}, \en{SwinUNETR}) και αποδοτικές εναλλακτικές για μοντελοποίηση
μακρινών εξαρτήσεων (\en{state space}-based, \en{SegMamba}). Με αυτόν τον τρόπο
εξετάζεται τόσο η επίδραση ισχυρού τοπικού \en{inductive bias} όσο και η
συμβολή μηχανισμών παγκόσμιου \en{context}.

Για κάθε αρχιτεκτονική εκτελέστηκε μία βασική εκπαίδευση
(\en{baseline run}) με το κοινό \en{pipeline}.
Επιπλέον πραγματοποιήθηκαν ενισχυμένα πειράματα (\en{stronger runs}) για
επιλεγμένα μοντέλα (π.\,χ. \en{SegResNet} και \en{SwinUNETR}), με στόχο να
διερευνηθεί η επίδραση ρυθμίσεων που αυξάνουν την ικανότητα του δικτύου ή/και
βελτιώνουν τη σταθερότητα σύγκλισης (π.\,χ. μεταβολές σε
\en{feature size, window size}, βάθος, κ.\,ά.).
Οι αποκλίσεις αυτές από τη βασική ρύθμιση καταγράφονται ρητά στις αντίστοιχες
υποενότητες αποτελεσμάτων.

\section{Υπολογιστικό περιβάλλον και εκτέλεση πειραμάτων}
\label{sec:proto_env}
Τα πειράματα υλοποιήθηκαν σε \en{Python/PyTorch} με τη βιβλιοθήκη
\en{MONAI} \cite{cardoso2022monai}. Η εκπαίδευση εκτελέστηκε σε περιβάλλον
\en{cloud} μέσω της πλατφόρμας \en{Kaggle Notebooks} (με επαλήθευση μέσω
τηλεφώνου), αξιοποιώντας \en{GPU} επιτάχυνση (π.χ. \en{NVIDIA T4} σε διαθέσιμη
διαμόρφωση) εντός του εβδομαδιαίου ορίου χρήσης που παρέχεται από την
πλατφόρμα.\footnote{Οι ακριβείς διαθέσιμοι πόροι και τα όρια χρήσης μπορεί να
μεταβάλλονται με τον χρόνο και εξαρτώνται από την πολιτική της πλατφόρμας.}

Οι εκτελέσεις πραγματοποιήθηκαν ως \emph{\en{non-interactive runs}} (\en{batch-style}
εκπαίδευση με καταγραφή \en{logs}/μετρικών), ώστε να διατηρείται σταθερή
η διαδικασία μεταξύ μοντέλων και να αποφεύγονται χειροκίνητες παρεμβάσεις.
Για αναπαραγωγιμότητα χρησιμοποιήθηκαν σταθερά \en{seeds} σε \en{Python},
\en{NumPy} και \en{PyTorch}, καθώς και κοινή δομή κώδικα για όλα τα μοντέλα
(με διαφοροποίηση κυρίως στην αρχικοποίηση της αρχιτεκτονικής).

\section{Οργάνωση δεδομένων και ροή φόρτωσης}
\label{sec:proto_dataflow}
Κάθε περιστατικό περιλαμβάνει έναν \en{3D MRI} όγκο και την αντίστοιχη
δυαδική μάσκα πλακούντα σε μορφή \en{NIfTI} (\en{\texttt{.nii.gz}}). Τα
δεδομένα μετατρέπονται σε λίστα από \en{dictionaries} (\en{paths} για
\en{\texttt{image}} και \en{\texttt{label}}), η οποία τροφοδοτείται σε
\en{Dataset} του \en{MONAI}.

Για επιτάχυνση, το αιτιοκρατικό τμήμα της προεπεξεργασίας προϋπολογίζεται μια φορά και αποθηκεύεται σε \en{disk cache} μέσω \textbf{\en{PersistentDataset}}.
Αντιθέτως, οι στοχαστικοί μετασχηματισμοί (\en{Random Augmentations}, εφαρμόζονται μόνο στο \en{training set}) εκτελούνται κάθε εποχή κατά τη φόρτωση των δεδομένων μέσω \en{DataLoader}. 
Αυτό συμβαίνει ώστε να έχουμε διαφορετικές παραλλαγές των ίδιων δειγμάτων χωρίς επαναλαμβανόμενο κόστος σταθερής προεπεξεργασίας.

\section{Ανάλυση στοίβας προεπεξεργασίας}
\label{sec:proto_preproc}

Η προεπεξεργασία σχεδιάστηκε με γνώμονα δύο βασικά χαρακτηριστικά του
προβλήματος: (α) την υψηλή ανισορροπία \en{background/foreground}
(ο πλακούντας καταλαμβάνει μικρό μέρος του όγκου) και (β) την ανάγκη
γεωμετρικής συνέπειας μεταξύ περιστατικών. Οι μετασχηματισμοί επιλέχθηκαν
από το \en{MONAI} \cite{monaitransforms}.

\subsection{Γεωμετρική εναρμόνιση και σταθεροποίηση εισόδου}
Το πρώτο στάδιο εξασφαλίζει ότι όλα τα δεδομένα «βλέπονται» από το μοντέλο
σε κοινό γεωμετρικό πλαίσιο:
\begin{itemize}
  \item \textbf{Φόρτωση και τυποποίηση:} ανάγνωση \en{NIfTI}, μεταφορά σε
        \en{tensor} και εξασφάλιση σωστού καναλιού (\en{channel-first}),
        ώστε οι επόμενοι μετασχηματισμοί να εφαρμόζονται ομοιόμορφα.
  \item \textbf{Επαναπροσανατολισμός (\en{Orientation}):} μετατροπή σε κοινό
        σύστημα αξόνων (\en{RAS}), ώστε να αποφεύγονται ασυνέπειες σε
        left/right, anterior/posterior κ.λπ.
  \item \textbf{Αναδειγματοληψία (\en{Spacing}):} μετασχηματισμός σε κοινό
        \en{voxel spacing} (π.χ. $(2,2,2)$\,\en{mm}), ώστε η μάθηση να μην
        επηρεάζεται από διαφορετικές φυσικές κλίμακες και ανομοιογενές
        \en{resolution} μεταξύ εξετάσεων.
\end{itemize}

\subsection{Κανονικοποίηση εντάσεων}
Οι \en{MRI} εντάσεις δεν είναι άμεσα συγκρίσιμες όπως σε \en{CT}, συνεπώς
εφαρμόζεται κανονικοποίηση με \en{percentiles} (π.χ. 2--99.9) και
χαρτογράφηση στο $[0,1]$. Η πρακτική αυτή (α) περιορίζει την επίδραση
outliers/θορύβου και (β) διευκολύνει τη σταθερότητα του optimization.

\subsection{Περιορισμός πεδίου (ROI) με \en{foreground cropping}}
Δεδομένης της μεγάλης έκτασης \en{background}, εφαρμόστηκε \en{CropForegroundd}
με \en{source\_key=label} και μικρό περιθώριο (\en{margin}) ώστε να
περιορίζεται το \en{FOV} γύρω από την περιοχή ενδιαφέροντος. Με τον τρόπο
αυτό μειώνεται δραστικά η σπατάλη υπολογισμού σε κενές περιοχές, αυξάνοντας
την πιθανότητα τα \en{patches} να περιέχουν χρήσιμη πληροφορία.

\subsection{Σταθεροποίηση διαστάσεων για συμβατότητα μοντέλων}
Τέλος, εφαρμόζεται:
\begin{itemize}
  \item \textbf{Padding σε σταθερό \en{roi\_size}} (π.χ. $(96,96,64)$), για
        ομοιόμορφη εκπαίδευση με \en{patch-based} στρατηγική.
  \item \textbf{\en{Divisible padding}} ώστε οι τελικές διαστάσεις να είναι
        πολλαπλάσια συγκεκριμένων παραγόντων (π.χ. $(32,32,16)$), κάτι που
        διευκολύνει αρχιτεκτονικές με downsampling/patch merging.
\end{itemize}

\section{Δειγματοληψία \en{patches} και επαύξηση δεδομένων}
\label{sec:proto_patches_aug}

Λόγω του μεγέθους των \en{3D} όγκων και περιορισμών μνήμης, η εκπαίδευση
πραγματοποιείται σε \en{patches} σταθερού μεγέθους (\en{roi\_size}).
Για την αντιμετώπιση της έντονης ανισορροπίας \en{background/foreground}
χρησιμοποιήθηκε \en{RandCropByPosNegLabeld}, ώστε να ελέγχεται η πιθανότητα
επιλογής \en{patches} που περιέχουν \en{foreground}.

Επιπλέον εφαρμόστηκε \textbf{στρατηγική \en{curriculum}} στην αναλογία
\en{pos/neg} κατά τη διάρκεια της εκπαίδευσης, με στόχο αρχικά να
σταθεροποιηθεί η μάθηση πάνω στο \en{foreground} και στη συνέχεια να
μειωθούν τα \en{false positives} μέσω σταδιακής εισαγωγής αρνητικών
δειγμάτων.

Για βελτίωση της γενίκευσης, εφαρμόστηκαν στοχαστικές επαυξήσεις
(\en{random flips}, ήπιες περιστροφές/αφινικοί μετασχηματισμοί, \en{Gaussian}
θόρυβος/εξομάλυνση), οι οποίες προσομοιώνουν ρεαλιστική μεταβλητότητα χωρίς
να αλλοιώνουν τη σημασιολογία της μάσκας.

\section{Συνάρτηση κόστους και βελτιστοποίηση}
\label{sec:proto_optim}

\subsection{Κριτήριο εκπαίδευσης}
Ως βασικό κριτήριο χρησιμοποιήθηκε η \en{DiceCELoss} (\en{Dice + Cross-Entropy}),
με \en{sigmoid} έξοδο και \en{include\_background=False}. Ο συνδυασμός
\en{Dice} και \en{CE} είναι πρακτικός σε έντονα ανισόρροπες τμηματοποιήσεις,
καθώς ο \en{Dice} στοχεύει άμεσα στην επικάλυψη, ενώ το \en{CE} συνεισφέρει
σταθερότητα και καλύτερη συμπεριφορά gradients σε πρώιμα στάδια σύγκλισης.

\subsection{\en{Optimizer}}
Χρησιμοποιήθηκε \en{AdamW} \cite{loshchilov2019adamw}, λόγω καλής πρακτικής
συμπεριφοράς σε \en{deep} δίκτυα και πιο ορθού χειρισμού του \en{weight decay}
σε σχέση με το κλασικό \en{Adam}. Οι υπερπαράμετροι (\en{learning rate, weight
decay}) διατηρήθηκαν κοινές μεταξύ μοντέλων όπου ήταν εφικτό, για δίκαιη
σύγκριση.

\subsection{\en{Scheduler}}
Ο ρυθμός μάθησης μεταβαλλόταν με \en{CyclicLR (triangular2)}
\cite{smith2017cyclical}, εντός ενός εύρους $[\texttt{\en{base\_lr}}, \texttt{\en{max\_lr}}]$.
Η κυκλική μεταβολή λειτουργεί ως μηχανισμός εξερεύνησης του \en{optimization
landscape}, μειώνοντας την ευαισθησία σε μία «μοναδική» επιλογή \en{learning rate}
και συχνά οδηγεί σε πιο σταθερή βελτίωση σε μεσαία/όψιμα στάδια.

\section{Επικύρωση και διαδικασία \en{inference}}
\label{sec:proto_validation}

\subsection{\en{Sliding Window Inference (SWI)}}
Η επικύρωση σε πλήρεις \en{3D} όγκους είναι συχνά αδύνατη σε μνήμη, ειδικά για
βαριά μοντέλα. Για τον λόγο αυτό εφαρμόστηκε \en{sliding-window inference}
με επικάλυψη (\en{overlap}) και \en{gaussian blending}, ώστε να συντίθεται
τελική πρόβλεψη σε όλο τον όγκο χωρίς να θυσιάζεται η ποιότητα στα όρια των
\en{patches}.

\subsection{\en{EMA (Exponential Moving Average)}}
Παράλληλα, χρησιμοποιήθηκε \en{EMA} των βαρών, δηλαδή εκθετικός κινητός μέσος
των παραμέτρων του μοντέλου. Η αξιολόγηση με \en{EMA} τείνει να είναι πιο
σταθερή από το στιγμιαίο \en{checkpoint}, ειδικά σε σχήματα με κυμαινόμενο
\en{learning rate}.

\subsection{Καταγραφή μετρικών και επιλογή \en{checkpoint}}
Η αξιολόγηση καταγράφει \en{Dice} (κύρια μετρική) και \en{IoU} σε επίπεδο
\en{3D} περιστατικού. Το καλύτερο checkpoint επιλέγεται βάσει της επίδοσης
στο \en{validation set}, ώστε να διατηρείται συνεπές σημείο αναφοράς μεταξύ
μοντέλων.

\section{Ρυθμίσεις εκπαίδευσης και σταθεροποίηση σύγκλισης}
\label{sec:proto_training_details}

Η εκπαίδευση πραγματοποιήθηκε για προκαθορισμένο αριθμό \en{epochs} με μικρό
\en{batch size} λόγω περιορισμών μνήμης. Για να προσεγγιστεί μεγαλύτερο
αποτελεσματικό \en{batch}, χρησιμοποιήθηκε \en{gradient accumulation}.
Παράλληλα, εφαρμόστηκε \en{mixed precision} (\en{AMP}) για μείωση της
κατανάλωσης \en{VRAM} και επιτάχυνση της εκτέλεσης σε \en{GPU}.

Για την αποφυγή υπερπροσαρμογής και τη συνεπή επιλογή τελικού μοντέλου,
αποθηκευόταν το καλύτερο \en{checkpoint} σύμφωνα με τη μετρική \en{Dice}
στο \en{validation set}, ενώ χρησιμοποιήθηκε \en{early stopping} όταν δεν
παρατηρούνταν βελτίωση για προκαθορισμένη \en{patience}.

\section{Παρουσίαση αποτελεσμάτων}
\label{sec:exp_results}

Τα αποτελέσματα παρουσιάζονται σε δύο επίπεδα:
\begin{itemize}
  \item \textbf{Ποσοτικά:} μετρικές \en{Dice/IoU} και απώλειες
        (\en{train/val loss}), με σύγκριση μεταξύ μοντέλων.
  \item \textbf{Ποιοτικά:} ενδεικτικές οπτικοποιήσεις προβλέψεων/σφαλμάτων
        σε αντιπροσωπευτικά περιστατικά.
\end{itemize}

Ο Πίνακας~\ref{tab:main_results} συνοψίζει τη βασική επίδοση ανά μοντέλο στο
\en{validation set}. Η αναλυτική ερμηνεία, συγκριτική συζήτηση και
\en{error analysis} παρουσιάζονται στο Κεφάλαιο~\ref{ch:discussion}.

\begin{table}[h]
\centering
\caption{Σύνοψη αποτελεσμάτων ανά αρχιτεκτονική στο \en{validation set}.}
\label{tab:main_results}
\begin{tabular}{lccc}
\hline
\textbf{Μοντέλο} & \en{\textbf{Dice}} & \en{\textbf{IoU}} & \en{\textbf{Val Loss}} \\
\hline
\en{U-Net}            & $0.829$  &  &  \\
\en{Attention U-Net}  & $0.846$  &  &  \\
\en{DynUNet}          & $0.846$ &  &  \\
\en{UNETR}            & $0.772$  &  &  \\
\en{SwinUNETR}        & $0.849$ &  &  \\
\en{SegResNet}        & $0.8601$  &  &  \\
\en{SegMamba}         & $0.8606$ &  &  \\
\hline
\end{tabular}
\end{table}
