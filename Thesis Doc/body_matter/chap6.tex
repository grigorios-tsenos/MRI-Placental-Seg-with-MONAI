\chapter{Αποτελέσματα Πειραματικής Αξιολόγησης}
\label{ch:results}

Στο κεφάλαιο αυτό παρουσιάζονται τα αποτελέσματα της συγκριτικής αξιολόγησης των αρχιτεκτονικών 
τμηματοποίησης που περιγράφηκαν στο Κεφάλαιο \ref{ch:experiments}. 
Όλα τα μοντέλα εκπαιδεύτηκαν και αξιολογήθηκαν με ενιαίο πειραματικό πρωτόκολλο 
(προεπεξεργασία, δειγματοληψία, βελτιστοποίηση, επικύρωση), ώστε οι διαφορές στο τέλος να αποδίδονται όσο το δυνατόν περισσότερο στην αρχιτεκτονική και όχι σε ασυνεπείς ρυθμίσεις ή διαδικασίες.

Πρώτα, παρατίθενται τα ποσοτικά αποτελέσματα στα δεδομένα αξιολόγησης μέσω μετρικών επικάλυψης 
(\en{Dice, IoU}) και της τιμής της απώλειας επικύρωσης (\en{validation loss}). 
Δεύτερον, συμπληρώνονται με ποιοτική αξιολόγηση μέσω οπτικών προβλέψεων έναντι \en{ground truth}, 
ως έλεγχος των αριθμητικών δεικτών ως προς το εάν αντιπροσωπεύουν την πραγματικότητα.

Στις επόμενες ενότητες παρουσιάζεται αρχικά η συνοπτική κατάταξη των μοντέλων
με βάση τη μέση επίδοση, και στη συνέχεια αναλύονται πιο λεπτομερώς οι τάσεις
ανά αρχιτεκτονική, με αναφορές τόσο στις καμπύλες εκπαίδευσης/επικύρωσης όσο
και στα οπτικά αποτελέσματα.

\section{Παρουσίαση αποτελεσμάτων}
\label{sec:exp_results}
Τα αποτελέσματα παρουσιάζονται σε δύο επίπεδα:
\begin{itemize}
  \item \textbf{Ποσοτικά:} μετρικές \en{Dice/IoU} και απώλειες (\en{train/val loss}), με σύγκριση μεταξύ μοντέλων.
  \item \textbf{Ποιοτικά:} ενδεικτικές οπτικοποιήσεις προβλέψεων/σφαλμάτων
        σε αντιπροσωπευτικά περιστατικά.
\end{itemize}
Ο Πίνακας~\ref{tab:main_results} συνοψίζει τη \textbf{καλύτερη} επίδοση κάθε μοντέλου στο 
\en{validation set}, όπως προέκυψε σε επίπεδο \en{3D} όγκου σε 120 \en{epochs}. 
Οι τιμές \en{Dice} χρησιμοποιούνται ως σημείο αναφοράς για την αναλυτικότερη ποιοτική και συγκριτική συζήτηση που ακολουθεί και αντιστοιχούν στη μέγιστη τιμή του \en{mean Dice} που επιτεύχθηκε σε κάποιο \en{epoch} εντός της εκπαίδευσης.

\begin{table}[!htbp]
\centering
\caption{Αποτελέσματα ανά αρχιτεκτονική στο \en{validation set}.}
\label{tab:main_results}
\begin{tabular}{lccc}
\hline
\textbf{Μοντέλο} & \en{\textbf{Dice}} & \en{\textbf{IoU}} & \en{\textbf{Val Loss}} \\
\hline
\en{U-Net}            & $0.829$  & $0.7109$  & $0.3739$ \\
\en{Attention U-Net}  & $0.846$  & $0.735$  & $0.2004$  \\
\en{DynUNet}          & $0.846$ & $0.7342$  & $0.1897$ \\
\en{UNETR}            & $0.772$  & $0.6345$ & $0.2842$  \\
\en{SwinUNETR}        & $0.849$ & $0.7401$ & $0.1838$ \\
\en{SegResNet 1}        & $0.8601$  & $0.7558$ & $0.1678$ \\
\en{SegResNet 2}        & $0.859$  & $0.7544$ & $0.1806$ \\
\en{SegMamba 1}         & $0.8606$ & $0.7566$ & $0.1685$ \\
\en{SegMamba 2}         & $0.8581$ & $0.7526$ & $0.1697$ \\
\hline
\end{tabular}
\end{table}

Σημειώνεται ότι οι μετρικές επικάλυψης αποτυπώνουν κυρίως τη συμφωνία ως προς το εμβαδό/όγκο της πρόβλεψης 
και δεν εγγυώνται πάντα οπτικά σωστά όρια σε όλες τις περιπτώσεις. 
Για τον λόγο αυτό, τα ποσοτικά αποτελέσματα του Πίνακα \ref{tab:main_results} 
ερμηνεύονται σε συνδυασμό με τις καμπύλες εκπαίδευσης/επικύρωσης και την ποιοτική επιθεώρηση προβλέψεων έναντι 
\en{ground truth} στις επόμενες ενότητες.

\section{Συνοπτική κατάταξη και κύρια ευρήματα}
\label{sec:results_ranking}
Ξεκινώντας από τον Πίνακα \ref{tab:main_results}, η κατάταξη των μοντέλων 
με βάση τη μέγιστη μέση τιμή του \en{Dice} δείχνει ότι η καλύτερη επίδοση επιτυγχάνεται από το 
\en{SegMamba 1} 
(\en{Dice}$=0.8606$) και έπειτα τα \en{SegResNet 2} (\en{Dice}$=0.859$) και 
\en{SegMamba 2} (\en{Dice}$=0.8581$). 
Οι διαφορές μέσα στα προαναφερθέντα είναι της τάξης του $\approx 0.002$--$0.003$ 
σε \en{Dice}.

Η εικόνα αυτή επιβεβαιώνεται και από τη συμπληρωματική μετρική \en{IoU}:
τα υψηλότερα \en{IoU} παρατηρούνται επίσης στα \en{SegMamba 1} ($0.7566$) και
\en{SegResNet 1} ($0.7558$), με τα υπόλοιπα μοντέλα της κορυφής να ακολουθούν
πολύ κοντά. Παράλληλα, οι τιμές \en{validation loss} είναι χαμηλότερες για τα
μοντέλα με καλύτερο \en{Dice} (π.χ. \en{SegResNet 1}: $0.1678$,
\en{SegMamba 1}: $0.1685$), γεγονός που είναι συμβατό με καλύτερη συνολική
βελτιστοποίηση. 
Ωστόσο, επειδή το \en{loss} αποτελεί σύνθετο κριτήριο και δεν
αντιστοιχεί μονοσήμαντα σε μια \en{overlap} μετρική, η τελική κατάταξη
στηρίζεται πρωτίστως στο \en{Dice} (και υποστηρίζεται από \en{IoU}).

Σε επίπεδο οικογενειών αρχιτεκτονικών, παρατηρείται ότι οι αποδοτικές
\en{CNN-based} προσεγγίσεις (\en{SegResNet}) και τα \en{state space-based}
μοντέλα (\en{SegMamba}) υπερέχουν συνολικά των \en{Transformer-based}
αρχιτεκτονικών στο συγκεκριμένο πρόβλημα/σύνολο δεδομένων. Ειδικότερα, το
\en{UNETR} εμφανίζει τη χαμηλότερη επίδοση (\en{Dice}$=0.772$,
\en{IoU}$=0.6345$), αποτελώντας σαφή
\en{outlier}. 
Αντίθετα, το \en{SwinUNETR} λειτουργεί ως το καλύτερο
\en{Transformer-based} μοντέλο (\en{Dice}$=0.849$, \en{IoU}$=0.7401$),
ωστόσο παραμένει κάτω από την ομάδα κορυφής κατά περίπου $0.01$ σε \en{Dice}.
Αξίζει να σχολιάσουμε το γεγονός πως το \en{U-Net} παρότι πετυχαίνει αξιοπρεπές \en{Dice}
($0.829$), εμφανίζει αισθητά υψηλότερο \en{validation loss} ($0.3739$) σε σχέση με τα περισσότερα μοντέλα. 
Αυτή η ασυμφωνία υποδηλώνει ότι η πρόβλεψη μπορεί να είναι επαρκής ως προς το \en{overlap} μετά το 
\en{thresholding}, αλλά οι πιθανότητες εξόδου είναι λιγότερο καλά βαθμονομημένες (δηλαδή πιο «αιχμηρές» και \en{overconfident} σε λάθη). 

Τέλος, οι παραλλαγές χωρητικότητας (\en{SegResNet 1} έναντι \en{SegResNet 2},
και \en{SegMamba 1} έναντι \en{SegMamba 2}) δείχνουν ότι η «βαρύτερη» ρύθμιση
μπορεί να προσφέρει μικρό αλλά μετρήσιμο κέρδος στην επικάλυψη
(π.χ. \en{SegResNet 1}: $0.8601$ έναντι $0.859$), χωρίς όμως να αλλάζει
δραστικά την κατάταξη. Στις επόμενες ενότητες διερευνάται αν αυτές οι μικρές
διαφορές συνοδεύονται από πιο σταθερή σύγκλιση ή/και πιο καθαρό οπτικό
περίγραμμα στις προβλέψεις.

\section{Καμπύλες εκπαίδευσης και σταθερότητα σύγκλισης}
\label{sec:results_curves}
Στα σχήματα \ref{fig:graphs1}, \ref{fig:graphs2} και \ref{fig:graphs3} παρουσιάζονται οι καμπύλες 
εκπαίδευσης για κάθε αρχιτεκτονική. Πρώτη καμπύλη αποτελεί τη μετρική \en{Dice} και η δεύτερη τα \en{training} και \en{validation losses} κατά τη διάρκεια των \en{epochs}.

\paragraph{Γενική εικόνα σύγκλισης.}
Σε όλες σχεδόν τις \en{CNN}-βασισμένες αρχιτεκτονικές παρατηρείται \textbf{ταχεία αρχική βελτίωση} του \en{validation Dice} στα πρώτα 5-15 \en{epochs},
συγκλίνοντας σχετικά νωρίς (σταδιακή, μικρή βελτίωση) μέχρι το τέλος της εκπαίδευσης. 
Αυτό υποδηλώνει ότι το μοντέλο μαθαίνει γρήγορα τη χονδρική μορφολογία του πλακούντα, ενώ οι επιπλέον εποχές συμβάλλουν κυρίως σε λεπτότερη προσαρμογή (όρια, μικρές ασυνέχειες, μείωση \en{false positives}).

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/history_attentionUnet.png}
    \caption{\en{Attention U-Net}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/history_dynunet.png}
    \caption{\en{DynUNet}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/history_SwinUNETR.png}
    \caption{\en{SwinUNETR}}
  \end{subfigure}
  \caption{Καμπύλες εκπαίδευσης: \en{Validation Dice} (πάνω) και \en{training/validation loss} (κάτω) για \en{Attention U-Net}, \en{DynUNet} και \en{SwinUNETR}. Το αστέρι και η κατακόρυφη διακεκομμένη γραμμή δείχνουν το \en{epoch} του καλύτερου \en{Dice}.}
  \label{fig:graphs1}
\end{figure}  

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\linewidth}
    \centering\includegraphics[width=\linewidth]{figures/history_segresLight.png}
    \caption{\en{SegResNet 2 (No of Filters = 32)}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\linewidth}
    \centering\includegraphics[width=\linewidth]{figures/history_segresHeavy.png}
    \caption{\en{SegResNet 1 (No of Filters = 64)}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering\includegraphics[width=\linewidth]{figures/history_UNET.png}
    \caption{\en{U-Net}}
  \end{subfigure}
  \caption{Καμπύλες εκπαίδευσης: \en{Validation Dice} (πάνω) και \en{training/validation loss} (κάτω) για \en{SegResNet 2}, \en{SegResNet 1} και \en{U-Net}. Το αστέρι και η κατακόρυφη διακεκομμένη γραμμή δείχνουν το \en{epoch} του καλύτερου \en{Dice}.}
  \label{fig:graphs2}
\end{figure}  

  
\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \centering\includegraphics[width=\textwidth]{figures/history_UNETR.png}
    \caption{\en{UNETR}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering\includegraphics[width=\textwidth]{figures/history_segmambaheavy.png}
    \caption{\en{SegMamba 1 (5 layers)}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering\includegraphics[width=\textwidth]{figures/history_segmamba.png}
    \caption{\en{SegMamba 2 (4 layers)}}
  \end{subfigure}
  \caption{Καμπύλες εκπαίδευσης: \en{Validation Dice} (πάνω) και \en{training/validation loss} (κάτω) για \en{UNETR}, \en{SegMamba 1} και \en{SegMamba 2}. Το αστέρι και η κατακόρυφη διακεκομμένη γραμμή δείχνουν το \en{epoch} του καλύτερου \en{Dice}.}
  \label{fig:graphs3}
\end{figure}  

\paragraph{Συγκριτική ερμηνεία καμπυλών.}
Οι \en{CNN}-βασισμένες αρχιτεκτονικές (\en{U-Net}, \en{Attention U-Net},
\en{DynUNet}, \en{SegResNet}) εμφανίζουν απότομη άνοδο του
\en{validation Dice} στα πρώτα $\sim$10--20 \en{epochs} και στη συνέχεια
σταθεροποίηση (\en{plateau}). Το μοτίβο αυτό είναι συμβατό με τον ισχυρό τοπικό
\en{inductive bias} των συνελίξεων, που επιτρέπει γρήγορη εκμάθηση
μορφολογίας/ορίων στο συγκεκριμένο, σχετικά περιορισμένο σύνολο δεδομένων.

\paragraph{\en{Transformer-based} συμπεριφορά.}
Το \en{UNETR} λειτουργεί ως \en{outlier}, επιτυγχάνοντας χαμηλότερο \en{best Dice},
γεγονός που συμφωνεί με τη συνολική του υστέρηση στον Πίνακα~\ref{tab:main_results}.
Αντίθετα, το \en{SwinUNETR} παρουσιάζει πιο ομαλή και σταδιακή βελτίωση και
ενώ δεν ξεπερνά την
κορυφή (\en{SegResNet}/\en{SegMamba}), αποδίδει καλύτερα απο το απλό \en{UNETR}. 
Το αποτέλεσμα είναι ενδεικτικό ότι η
ιεραρχική προσοχή με τοπικά παράθυρα του \en{Swin} είναι πιο κατάλληλη (και πιο
σταθερή) από έναν \en{ViT-style encoder} \cite{hatamizadeh2022swinunetr} στο
συγκεκριμένο πρόβλημα.

\paragraph{\en{SSM/Mamba-based} συμπεριφορά και χωρητικότητα.}
Οι παραλλαγές \en{SegMamba} συγκλίνουν γρήγορα σε υψηλές τιμές \en{Dice} και
παραμένουν σταθερά στην κορυφή. Παράλληλα, οι «βαρύτερες» ρυθμίσεις
(\en{SegResNet 1, SegMamba 1}) δίνουν μικρό αλλά μετρήσιμο πλεονέκτημα
έναντι των ελαφρύτερων εναλλακτικών, χωρίς να αλλάζουν δραστικά τη συνολική εικόνα.

\paragraph{Σταθερότητα και γενίκευση.}
Οι καμπύλες \en{training} και \en{validation loss} μειώνονται παράλληλα και
δεν παρατηρείται έντονη απόκλιση που να υποδεικνύει ισχυρή υπερπροσαρμογή στο
εξεταζόμενο εύρος \en{epochs}. Το καλύτερο \en{checkpoint} ορίζεται ως το
\en{epoch} μέγιστου \en{validation Dice} (κατακόρυφη γραμμή στα
γραφήματα), το οποίο εμφανίζεται συνήθως σε μεταγενέστερο \en{epoch}, ενώ οι
μεγαλύτερες βελτιώσεις έχουν ήδη πραγματοποιηθεί νωρίτερα.

\paragraph{Σύνδεση με ποιοτική αξιολόγηση.}
Στην επόμενη ενότητα εξετάζονται οπτικά παραδείγματα προβλέψεων και τυπικών
σφαλμάτων, ώστε να αξιολογηθεί κατά πόσο οι διαφορές στο \en{Dice/IoU}
αντιστοιχούν σε ουσιαστικές διαφορές στην ποιότητα ορίων.

\FloatBarrier

%______________________ VISUAL PROVLEPSEIS KATW

\section{Ποιοτική αξιολόγηση προβλέψεων}
\label{sec:results_qual}

Η ποιοτική αξιολόγηση συμπληρώνει τις ποσοτικές μετρικές του Πίνακα
\ref{tab:main_results}, καθώς οι μετρικές επικάλυψης (\en{Dice/IoU})
αποτυπώνουν κυρίως τη συμφωνία ως προς τον όγκο και δεν εγγυώνται πάντα
αντίστοιχη ακρίβεια στα όρια ή στα λεπτά τμήματα της δομής. Στα σχήματα που
ακολουθούν παρουσιάζονται \textbf{ενδεικτικές τομές} από δύο περιστατικά
(\en{Sample 1/2}) και η σύγκριση: \en{MRI slice} (αριστερά), \en{ground truth}
μάσκα (κέντρο) και δυαδική πρόβλεψη (δεξιά). Ο πλακούντας απεικονίζεται με
πράσινο και το υπόβαθρο με κόκκινο.

Κατά την οπτική επιθεώρηση εξετάζονται κυρίως:
\begin{itemize}
  \item \textbf{Ύπο- ή ύπερ-τμηματοποίηση},
  \item \textbf{συνέχεια/συνοχή} της μάσκας (τρύπες ή κατατμήσεις),
  \item \textbf{ψευδοθετικά} (\en{false positives}) ως απομονωμένες περιοχές,
  \item \textbf{ποιότητα ορίων} (ομαλότητα και μορφολογική συνέπεια).
\end{itemize}

\paragraph{Συμφωνία ποιοτικών και ποσοτικών αποτελεσμάτων.}
Συνολικά, η οπτική εικόνα επιβεβαιώνει την κατάταξη της
Ενότητας \ref{sec:results_ranking}. Τα μοντέλα με την υψηλότερη επίδοση σε
\en{Dice/IoU} (\en{SegMamba} και \en{SegResNet}) παράγουν πιο συνεπείς και
``καθαρές'' μάσκες, με όρια που ακολουθούν καλύτερα τη μορφολογία του
πλακούντα και με ελάχιστα ψευδοθετικά. Αντίθετα, το \en{UNETR}, που είναι
ποσοτικά ο ασθενέστερος \en{outlier}, εμφανίζει ορατές αστοχίες (ανομοιόμορφα
περιγράμματα, τμηματοποιήσεις εκτός στόχου και μικρές απομονωμένες περιοχές),
οι οποίες εξηγούν τη χαμηλή του \en{IoU} και το υψηλότερο \en{validation loss}.

\paragraph{\en{CNN-based} μοντέλα.}
Τα \en{U-Net}, \en{Attention U-Net} και \en{DynUNet} αποδίδουν γενικά σωστή
γεωμετρία και συνεχείς μάσκες, με αποκλίσεις που εμφανίζονται κυρίως στα άκρα
και σε λεπτές περιοχές (ελαφρά υπο- ή υπερ-τμηματοποίηση). Η \en{Attention U-Net}
και το \en{DynUNet} δείχνουν πιο σταθερή συμπεριφορά από το βασικό \en{U-Net},
συμβατό με το μικρό αλλά μετρήσιμο κέρδος στις μετρικές
(\en{Dice}$\approx 0.846$ έναντι $0.829$). Παράλληλα, το \en{U-Net} παρότι
παρουσιάζει αποδεκτή επικάλυψη, εμφανίζει μεγαλύτερο \en{validation loss}
(Πίνακας \ref{tab:main_results}), κάτι που είναι ενδεικτικό ότι το \en{loss}
(\en{Dice + CE}) είναι πιο ευαίσθητο σε αβεβαιότητα/λάθη κοντά στα όρια,
ακόμη και όταν η τελική δυαδική μάσκα (μετά το \en{thresholding}) είναι οπτικά
ικανοποιητική.

\paragraph{\en{Transformer-based} μοντέλα.}
Το \en{SwinUNETR} παράγει συνεπείς προβλέψεις με καλό περιορισμό των
ψευδοθετικών, κάτι που συμφωνεί με το ότι αποτελεί το καλύτερο
\en{Transformer-based} μοντέλο της σύγκρισης (\en{Dice}$=0.849$). Ωστόσο, σε
ορισμένα σημεία η πρόβλεψη είναι πιο ``συντηρητική'' (ελαφρά υπο-τμηματοποίηση
σε λεπτές προεξοχές), γεγονός που μπορεί να συμβάλλει στη διαφορά $\sim 0.01$
σε \en{Dice} από την κορυφή. Αντίθετα, το \en{UNETR} εμφανίζει πιο ασταθή
συμπεριφορά, με εμφανή \en{false positives} και ανομοιόμορφα περιγράμματα, τα
οποία υποβαθμίζουν τόσο την \en{IoU} όσο και την αντιληπτή ποιότητα ορίων.

\paragraph{Μοντέλα κορυφής: \en{SegResNet} και \en{SegMamba}.}
Τα \en{SegResNet} και \en{SegMamba} δίνουν, στις ενδεικτικές περιπτώσεις,
προβλέψεις πολύ κοντά στο \en{ground truth}: η μάσκα είναι συνεχής (χωρίς
``τρύπες'') και τα όρια ακολουθούν πιο πιστά τη μορφολογία. Οι διαφορές μεταξύ
``βαριάς'' και ``ελαφριάς'' παραλλαγής είναι μικρές και συμφωνούν με τις
αντίστοιχα μικρές διαφορές στις μετρικές (\en{Dice} στην τρίτη δεκαδική).

\paragraph{Περιορισμοί της οπτικής σύγκρισης.}
Οι απεικονίσεις αφορούν μεμονωμένες \en{2D} τομές, ενώ οι μετρικές
υπολογίζονται σε \en{3D} όγκους. Επομένως, μικρές τοπικές αποκλίσεις μπορεί να
μην είναι αντιπροσωπευτικές για το σύνολο του όγκου, αλλά παραμένουν χρήσιμες
για την κατανόηση τυπικών σφαλμάτων και την ερμηνεία των ποσοτικών δεικτών.

\begin{Illustration}[!h]
  \centering
  \includegraphics[width=0.68\linewidth]{figures/segmentation_masks_AttentionUnet.png}
  \caption{\en{Attention U-Net}}
\end{Illustration}

\begin{Illustration}[!h]
  \centering
  \includegraphics[width=0.68\linewidth]{figures/segmentation_masks_DynUNet.png}
  \caption{\en{DynUNet}}
\end{Illustration}

\begin{Illustration}[!h]
  \centering
  \includegraphics[width=0.68\linewidth]{figures/segmentation_masks_SwinUNETR.png}
  \caption{\en{SwinUNETR}}
\end{Illustration}


\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_SegResHeavy.png}
  \caption{\en{SegResNet 1 (No of Filters = 64)}}
\end{Illustration}

\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_SegResLight.png}
  \caption{\en{SegResNet 2 (No of Filters = 32)}}
\end{Illustration}

\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_unet.png}
  \caption{\en{U-Net}}
\end{Illustration}




\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_UNETR.png}
  \caption{\en{UNETR}}
\end{Illustration}
\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_segmambaHEAVY.png}
  \caption{\en{SegMamba 1 (5 layers)}}
\end{Illustration}
\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_segmambaLIGHT.png}
  \caption{\en{SegMamba 2 (4 layers)}}
\end{Illustration}





\FloatBarrier

\section{Σύγκριση με δημοσιευμένα αποτελέσματα}
\label{sec:results_literature_compare}

Για να τοποθετηθούν τα ευρήματα της παρούσας εργασίας σε ευρύτερο πλαίσιο,
παρατίθεται στον Πίνακα~\ref{tab:literature_comparison} συνοπτική σύγκριση με
σχετικές μελέτες τμηματοποίησης πλακούντα σε \en{MRI}
\cite{shahedi2021placenta,shahedi2022automatic,liu2023evaluation,huang2023prenatal,lee2023mrfmas,saito2025planets}.

\begin{table}[!htbp]
\centering
\scriptsize
\setlength{\tabcolsep}{2.5pt}
\renewcommand{\arraystretch}{1.12}
\caption{Σύνοψη αποτελεσμάτων από σχετικές μελέτες τμηματοποίησης πλακούντα σε \en{MRI}.}
\label{tab:literature_comparison}
\begin{tabular}{p{3.0cm}p{2.0cm}p{3.5cm}p{4.0cm}p{4.0cm}}
\hline
\textbf{Μελέτη} & \textbf{Μοντέλο} & \textbf{Δεδομένα / \en{split}} & \textbf{Μετρική πλακούντα} & \textbf{Σχόλιο} \\
\hline
\en{Shahedi et al.} 2022 \cite{shahedi2022automatic}
& \en{CNN--based}
& 181 \en{total} (\en{train}=157, \en{val}=24) + \en{test}=60
& \en{DSC}=0.80
& Μητρική κοιλότητα: \en{DSC}=0.92. \\

\en{Shahedi et al.} 2021 \cite{shahedi2021placenta}
& Δύο \en{CNN--based}
& 70 \en{total}, έλεγχος σε 20 (\en{normal}) και 50 (\en{\-normal+PAS})
& \en{DSC}=0.82 (\en{\-normal}), 0.83 (\en{+PAS})
& Μητρική κοιλότητα: \en{DSC}=0.92 και 0.88 αντίστοιχα. \\ 


\en{Liu et al.} 2023 \cite{liu2023evaluation}
& \en{SADL}
& 154 \en{total}, \en{train}=108, \en{val}=15, \en{test}=31
& \en{DSC}=0.83$\pm$0.06, 0.84$\pm$0.05 
& \en{UNet achieved}: ($0.77, 0.76$). \\

\en{Huang et al.} 2023 \cite{huang2023prenatal}
& \en{CNN--based} 
& 241 (\en{axial}), και 101 (\en{sagittal\-}) \en{MRI}
& \en{DSC}=0.82 (\en{axial}), 0.82 (\en{sagittal})
& Μητρική κοιλότητα: \en{DSC}=0.87 (\en{axial}), 0.92 (\en{sagittal}). \\

\en{Lee et al.} 2023 \cite{lee2023mrfmas}
& \en{MRF--MAS vs UNet}
& 390 \en{total}, \en{train}=312, \en{test}=78
& \en{Dice}=0.8992 (\en{MRF-MAS}), \en{U-Net Dice}=0.8632
& Αναφορά και \en{IoU}=0.8169 για το προτεινόμενο μοντέλο. \\

\en{Saito et al.} 2025 \cite{saito2025planets}
& \en{PlaNet-S (UNet+SegNeXt)}
& 1090 \en{total}, 875 \en{train}-215 \en{test}
& \en{IoU}=0.78$\pm$0.10 (\en{PlaNet-S})
& \en{U-Net IoU}=0.73$\pm$0.13, \en{DS-transUNet IoU}=0.64$\pm$0.16. \\

\textbf{Παρούσα εργασία} 
& \en{UNet}
& 137 περιπτώσεις, \en{train}=109, \en{val}=28
& \en{Dice}=0.829, \en{IoU}=0.7109 
& Ενιαίο πρωτόκολλο σε 9 διαμορφώσεις μοντέλων και αξιολόγηση σε \en{3D} όγκους. 
\\

\textbf{Παρούσα εργασία} 
& \en{SegMamba 1}
& 
& \en{Dice}=0.8606, \en{IoU}=0.7566
& Απέδωσε καλύτερα απο τις άλλες διαμορφώσεις \\


\hline
\end{tabular}
\end{table}

Η παραπάνω σύγκριση είναι \textbf{ενδεικτική} και όχι αυστηρά αντικειμενική
, επειδή τα πειράματα δεν έχουν εκτελεστεί σε κοινό σύνολο
δεδομένων ή ενιαίο πρωτόκολλο. 
Παρά τα παραπάνω, οι τιμές επικάλυψης της παρούσας εργασίας
(\en{Dice}$=0.8606$, \en{IoU}$=0.7566$) κινούνται στο ίδιο εύρος με τη
σύγχρονη βιβλιογραφία για τμηματοποίηση πλακούντα σε \en{MRI}, κάτι που
υποστηρίζει τη συνολική εγκυρότητα της πειραματικής μεθοδολογίας.

\section{Συζήτηση και ερμηνεία}
 
\label{sec:results_discussion}

Στην ενότητα αυτή συντίθενται τα ποσοτικά ευρήματα (Πίνακας~\ref{tab:main_results}
και καμπύλες εκπαίδευσης) με την ποιοτική επιθεώρηση (Ενότητα~\ref{sec:results_qual}),
με στόχο να δοθεί συνεκτική ερμηνεία των διαφορών μεταξύ των αρχιτεκτονικών και
να αποσαφηνιστεί ποια συμπεράσματα είναι σταθερά, αλλά και ποιοι παράγοντες
επηρεάζουν την αξιοπιστία/γενίκευση των αποτελεσμάτων.

\paragraph{Σύνοψη επιδόσεων και κλίμακα διαφορών.}
Η συνολική εικόνα δείχνει ότι οι καλύτερες επιδόσεις στο \en{validation set}
συγκεντρώνονται σε μια ``ομάδα κορυφής'' γύρω από \en{Dice} $0.86$:
\en{SegMamba 1} (\en{Dice}$=0.8606$) και \en{SegResNet 1/2}
(\en{Dice}$=0.8601/0.859$), με πολύ μικρές μεταξύ τους διαφορές
(περίπου $0.002$--$0.003$). Το \en{SwinUNETR} (\en{Dice}$=0.849$) είναι
ανταγωνιστικό, αλλά παραμένει χαμηλότερα από την κορυφή κατά περίπου $0.01$ σε
\en{Dice}, αλλά κατα $0.02$ παραπάνω απο το \en{standard UNet}, 
ενώ το \en{UNETR} αποτελεί σαφή \en{outlier} με αισθητά χαμηλότερη
επικάλυψη (\en{Dice}$=0.772$). Η μικρή απόσταση εντός της κορυφής υποδηλώνει
ότι, για το συγκεκριμένο σύνολο δεδομένων και πρωτόκολλο, η επίδοση τείνει να
κορεστεί: περαιτέρω βελτιώσεις αναμένονται να είναι οριακές και πιθανόν να
εξαρτώνται περισσότερο από λεπτομέρειες \en{pre-processing}, δειγματοληψίας
\en{patches} ή ποιότητας επισημειώσεων, παρά από ριζικά διαφορετική
αρχιτεκτονική.

\paragraph{Ερμηνεία υπεροχής \en{CNN}/\en{SSM} προσεγγίσεων.}
Τα αποτελέσματα υποδεικνύουν ότι οι \en{CNN}-βασισμένες λύσεις
(\en{SegResNet}, \en{DynUNet}, \en{Attention U-Net}) και τα \en{SSM-based}
μοντέλα (\en{SegMamba}) είναι ιδιαίτερα κατάλληλα για τμηματοποίηση πλακούντα
σε \en{3D MRI}. Μια εύλογη ερμηνεία είναι ότι το πρόβλημα κυριαρχείται από
τοπική μορφολογία και συνέπεια ορίων, όπου ο \en{inductive bias} των συνελίξεων και 
η αποδοτική μοντελοποίηση εξαρτήσεων των \en{SSM} αρκούν για να
ανακτηθεί το απαραίτητο \en{context}, χωρίς \en{self-attention} σε όλο τον όγκο. Η ποιοτική
αξιολόγηση συμφωνεί με το παραπάνω: 
τα μοντέλα κορυφής εμφανίζουν πιο συνεκτικές
μάσκες και περιορισμένα \en{false positives}, με όρια που ακολουθούν καλύτερα τη
μορφολογία του \en{ground truth}.

\paragraph{Σχόλια για \en{Transformer} μοντέλα: \en{UNETR} έναντι \en{SwinUNETR}.}
Η αισθητά χαμηλότερη επίδοση του \en{UNETR} είναι συμβατή με τη γενικότερη
παρατήρηση ότι \en{ViT}-τύπου \en{encoders} τείνουν να απαιτούν μεγαλύτερο
όγκο δεδομένων, προσεκτικότερο \en{regularization} και/ή πιο πλούσια
προεκπαίδευση, ώστε να αποδώσουν ανταγωνιστικά σε ιατρική τμηματοποίηση.
Αντίθετα, το \en{SwinUNETR} εμφανίζει πιο σταθερή και καλύτερη συμπεριφορά,
πιθανώς επειδή ενσωματώνει ισχυρότερη τοπικότητα (ιεραρχικά \en{windows} και
\en{patch merging}), κάτι που λειτουργεί ως πιο κατάλληλος \en{prior} για
\en{3D} δεδομένα με περιορισμένο αριθμό περιπτώσεων. Οπτικά, αυτό αποτυπώνεται
σε πιο ``καθαρά'' όρια και σε περιορισμό των σποραδικών ψευδοθετικών περιοχών,
σε σύγκριση με το \en{UNETR}.

\paragraph{Σχέση \en{Dice/IoU} και \en{validation loss}.}
Παρότι το \en{validation loss} ακολουθεί γενικά την κατάταξη των μοντέλων, δεν
είναι πλήρως μονοσήμαντο ως προς τις μετρικές επικάλυψης. Η περίπτωση του
\en{U-Net} (ικανοποιητικό \en{Dice} αλλά υψηλότερο \en{loss}) υποδηλώνει ότι ο
συνδυα\-σμός \en{Dice + CE} επηρεάζεται από τη βαθμονόμηση της εξόδου και από
λάθη κοντά στα όρια που μπορεί να μην αλλάζουν δραστικά το τελικό \en{overlap}
μετά το \en{thresholding}. Έτσι, οι μετρικές επικάλυψης πρέπει να ερμηνεύονται
συμπληρωματικά με το \en{loss} και, ιδανικά, με \en{boundary}-ευαίσθητες
μετρικές όταν το ζητούμενο είναι ακριβής εντοπισμός ορίων.

\paragraph{Ακρίβεια έναντι υπολογιστικού κόστους.}
Οι παραλλαγές χωρητικότητας (\en{SegResNet 1} έναντι \en{SegResNet 2} και
\en{SegMamba 1} έναντι \en{SegMamba 2}) προσφέρουν μόνο μικρό κέρδος στην
επικάλυψη. Αυτό πρακτικά σημαίνει ότι, σε περιβάλλοντα με περιορισμένους πόρους
(\en{VRAM}/χρόνος), μια ελαφρύτερη διαμόρφωση μπορεί να αποτελεί ελκυστική
επιλογή, χωρίς σημαντική θυσία ακρίβειας. 
Επίσης, παρότι το \en{SwinUNETR} επιτυγχάνει ανταγωνιστική επίδοση (σε \en{Dice}) και 
βρίσκεται πολύ κοντά στα κορυφαία \en{CNN-based} μοντέλα, η επί\-τευξη αυτής της επίδοσης συνοδεύεται από σημαντικά αυξημένο υπολογιστικό κόστος. 
Η \en{Transformer-based} δομή του σε \en{3D patches} και ιεραρχικό \en{patch merging} 
οδηγεί σε μεγαλύ\-τερο χρόνο άνα εποχή και αυξημένες απαιτήσεις μνήμης σε σύγκριση με αποδοτικότερες 
\en{CNN} επιλογές όπως το \en{SegResNet} ή ακόμα το \en{DynUNet}. 
Συνεπώς, το \en{SwinUNETR} αποτελεί ισχυρή επιλογή απο πλευράς απόδοσης, αλλά 
έχοντας το υπολογιστικό κόστος υπόψιν, οι εναλλακτικές καθίστανται προτιμότερες.


\paragraph{Περιορισμοί και παράγοντες γενίκευσης.}
Με τα παραπάνω συμπεράσματα πρέπει να μη ξεχνάμε και τα ακόλουθα: 
\begin{itemize}
  \item οι μετρικές προέρχονται από ένα \en{validation split} και όχι από ανεξάρτητο \en{test set} ή \en{cross-validation},
  \item οι ποιοτικές απεικονίσεις βασίζονται σε μεμονωμένες \en{2D} τομές, ενώ η αξιολόγηση είναι \en{3D}, 
\end{itemize}
Παρόλα αυτά, επειδή όλες οι αρχιτεκτονικές αξιολογούνται με κοινό πρωτόκολλο,
τα συγκριτικά συμπεράσματα (η σχετική κατάταξη και τα τυπικά σφάλματα) είναι
ισχυρότερα από την απόλυτη τιμή της επίδοσης.

\paragraph{Τελική αποτίμηση.}
Συνοψίζοντας, τα αποτελέσματα δείχνουν ότι τα \en{SegMamba} και \en{SegResNet}
αποτελούν τις πιο αποτελεσματικές επιλογές για το συγκεκριμένο πρόβλημα,
επιτυγχάνοντας την καλύτερη ισορροπία ποσοτικής επίδοσης και οπτικής συνέπειας.
Το \en{SwinUNETR} παραμένει μια ανταγωνιστική \en{Transformer}-βασισμένη εναλλακτική,
ενώ το \en{UNETR} δεν αποδίδει ικανοποιητικά υπό τις συγκεκριμένες συνθήκες
δεδομένων και πρωτοκόλλου.

\paragraph{Κύρια συμπεράσματα κεφαλαίου.}
\begin{itemize}
  \item Η οπτική αξιολόγηση ευθυγραμμίζεται με τις μετρικές \en{Dice/IoU}: τα \en{SegMamba} και \en{SegResNet} δίνουν πιο συνεκτικές μάσκες με λιγότερα ψευδοθετικά και καλύτερη μορφολογική συμφωνία.
  \item Το \en{SwinUNETR} είναι η πιο ανταγωνιστική \en{Transformer}-βασισμένη λύση, αλλά παραμένει ελαφρώς χαμηλότερα από την κορυφή, ενώ το \en{UNETR} εμφανίζει σαφώς ασθενέστερη γενίκευση στο συγκεκριμένο \en{split}.
  \item Οι διαφορές μεταξύ των κορυφαίων μοντέλων είναι μικρές· επομένως, σε πρακτικά σενάρια η επιλογή μπορεί να καθοδηγηθεί από υπολογιστικούς περιορισμούς (\en{VRAM}, χρόνος \en{inference}) και επιχειρησιακά κριτήρια, με ελάχιστη επίπτωση στην τελική επικάλυψη.
\end{itemize}

