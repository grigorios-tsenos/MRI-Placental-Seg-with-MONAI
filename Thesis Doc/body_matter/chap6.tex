\chapter{Αποτελέσματα Πειραματικής Αξιολόγησης}
\label{ch:results}

Στο κεφάλαιο αυτό παρουσιάζονται τα αποτελέσματα της συγκριτικής αξιολόγησης των αρχιτεκτονικών 
τμηματοποίησης που περιγράφηκαν στο Κεφάλαιο \ref{ch:experiments}. 
Όλα τα μοντέλα εκπαιδεύτηκαν και αξιολογήθηκαν με ενιαίο πειραματικό πρωτόκολλο 
(προεπεξεργασία, δειγματοληψία, βελτιστοποίηση, επικύρωση), ώστε οι διαφορές στο τέλος να αποδίδονται όσο το δυνατόν περισσότερο στην αρχιτεκτονική και όχι σε ασυνεπείς ρυθμίσεις ή διαδικασίες.

Πρώτα, παρατίθενται τα ποσοτικά αποτελέσματα  στα δεδομένα αξιολόγησης μέσω μετρικών επικάλυψης 
(\en{Dice, IoU}) και της τιμής της απώλειας επικύρωσης (\en{validation loss}). 
Δεύτερον, συμπληρώνονται με ποιοτική αξιολόγηση μέσω οπτικών προβλέψεων έναντι \en{ground truth}, 
ώς αξιολόγηση των αριθμητικών δείκτων για το εάν αντιπροσωπεύουν την πραγματικότητα.

Στις επόμενες ενότητες παρουσιάζεται αρχικά η συνοπτική κατάταξη των μοντέλων
με βάση τη μέση επίδοση, και στη συνέχεια αναλύονται πιο λεπτομερώς οι τάσεις
ανά αρχιτεκτονική, με αναφορές τόσο στις καμπύλες εκπαίδευσης/επικύρωσης όσο
και στα οπτικά αποτελέσματα.

\section{Παρουσίαση αποτελεσμάτων}
\label{sec:exp_results}
Τα αποτελέσματα παρουσιάζονται σε δύο επίπεδα:
\begin{itemize}
  \item \textbf{Ποσοτικά:} μετρικές \en{Dice/IoU} και απώλειες (\en{train/val loss}), με σύγκριση μεταξύ μοντέλων.
  \item \textbf{Ποιοτικά:} ενδεικτικές οπτικοποιήσεις προβλέψεων/σφαλμάτων
        σε αντιπροσωπευτικά περιστατικά.
\end{itemize}
Ο Πίνακας~\ref{tab:main_results} συνοψίζει τη \textbf{καλύτερη} επίδοση κάθε μοντέλου στο 
\en{validation set}, όπως προέκυψε σε επίπεδο \en{3D} όγκου σε 120 \en{epochs}. 
Οι τιμές \en{Dice} χρησιμοποιούνται ως σημείο αναφοράς για την αναλυτικότερη ποιοτική και συγκριτική συζήτηση που ακολουθεί. (μέγιστη τιμή του \en{mean Dice} άνα \en{epoch})

\begin{table}[!htbp]
\centering
\caption{Αποτελέσματα ανά αρχιτεκτονική στο \en{validation set}.}
\label{tab:main_results}
\begin{tabular}{lccc}
\hline
\textbf{Μοντέλο} & \en{\textbf{Dice}} & \en{\textbf{IoU}} & \en{\textbf{Val Loss}} \\
\hline
\en{U-Net}            & $0.829$  & $0.7109$  & $0.3739$ \\
\en{Attention U-Net}  & $0.846$  & $0.735$  & $0.2004$  \\
\en{DynUNet}          & $0.846$ & $0.7342$  & $0.1897$ \\
\en{UNETR}            & $0.772$  & $0.6345$ & $0.2842$  \\
\en{SwinUNETR}        & $0.849$ & $0.7401$ & $0.1838$ \\
\en{SegResNet 1}        & $0.8601$  & $0.7558$ & $0.1678$ \\
\en{SegResNet 2}        & $0.859$  & $0.7544$ & $0.1806$ \\
\en{SegMamba 1}         & $0.8606$ & $0.7566$ & $0.1685$ \\
\en{SegMamba 2}         & $0.8581$ & $0.7526$ & $0.1697$ \\
\hline
\end{tabular}
\end{table}

Σημείωνεται ότι οι μετρικές επικάλυψης αποτυπώνουν κυρίως τη συμφωνία ως προς το εμβαδό/όγκο της πρόβλεψης 
και δεν εγγυώνται πάντα οπτικά σωστά όρια σε όλες τις περιπτώσεις. 
Για τον λόγο αυτό, τα ποσοτικά αποτελέσματα του Πίνακα \ref{tab:main_results} 
ερμηνεύονται σε συνδυασμό με τις καμπύλες εκπαίδευσης/επικύρωσης και την ποιοτική επιθεώρηση προβλέψεων έναντι 
\en{ground truth} στις επόμενες ενότητες.

\section{Συνοπτική κατάταξη και κύρια ευρήματα}
\label{sec:results_ranking}
Ξεκινώντας από τον Πίνακα \ref{tab:main_results}, η κατάταξη των μοντέλων 
με βάση τη μέγιστη μέση τιμή του \en{Dice} δείχνει ότι η καλύτερη επίδοση επιτυγχάνεται από το 
\en{SegMamba 1} 
(\en{Dice}$=0.8606$) και έπειτα τα \en{SegResNet 2} (\en{Dice}$=0.859$) και 
\en{SegMamba 2} (\en{Dice}$=0.8581$). 
Οι διαφορές μέσα στα προαναφερθέντα είναι της τάξης του $\approx 0.002$--$0.003$ 
σε \en{Dice}.

Η εικόνα αυτή επιβεβαιώνεται και από τη συμπληρωματική μετρική \en{IoU}:
τα υψηλότερα \en{IoU} παρατηρούνται επίσης στα \en{SegMamba 1} ($0.7566$) και
\en{SegResNet 1} ($0.7558$), με τα υπόλοιπα μοντέλα της κορυφής να ακολουθούν
πολύ κοντά. Παράλληλα, οι τιμές \en{validation loss} είναι χαμηλότερες για τα
μοντέλα με καλύτερο \en{Dice} (π.χ. \en{SegResNet 1}: $0.1678$,
\en{SegMamba 1}: $0.1685$), γεγονός που είναι συμβατό με καλύτερη συνολική
βελτιστοποίηση. 
Ωστόσο, επειδή το \en{loss} αποτελεί σύνθετο κριτήριο και δεν
αντιστοιχεί μονοσήμαντα σε μια \en{overlap} μετρική, η τελική κατάταξη
στηρίζεται πρωτίστως στο \en{Dice} (και υποστηρίζεται από \en{IoU}).

Σε επίπεδο οικογενειών αρχιτεκτονικών, παρατηρείται ότι οι αποδοτικές
\en{CNN-based} προσεγγίσεις (\en{SegResNet}) και τα \en{state space-based}
μοντέλα (\en{SegMamba}) υπερέχουν συνολικά των \en{Transformer-based}
αρχιτεκτονικών στο συγκεκριμένο πρόβλημα/σύνολο δεδομένων. Ειδικότερα, το
\en{UNETR} εμφανίζει τη χαμηλότερη επίδοση (\en{Dice}$=0.772$,
\en{IoU}$=0.6345$), αποτελώντας σαφή
\en{outlier}. 
Αντίθετα, το \en{SwinUNETR} λειτουργεί ως το καλύτερο
\en{Transformer-based} μοντέλο (\en{Dice}$=0.849$, \en{IoU}$=0.7401$),
ωστόσο παραμένει κάτω από την ομάδα κορυφής κατά περίπου $0.01$ σε \en{Dice}.
Αξίζει να σχολιάσουμε το γεγονός πως το \en{U-Net} παρότι πετυχαίνει αξιοπρεπές \en{Dice}
($0.829$), εμφανίζει αισθητά υψηλότερο \en{validation loss} ($0.3739$) σε σχέση με τα περισσότερα μοντέλα. 
Αυτή η ασυμφωνία υποδηλώνει ότι η πρόβλεψη μπορεί να είναι επαρκής ως προς το \en{overlap} μετά το 
\en{thresholding}, αλλά οι πιθανότητες εξόδου είναι λιγότερο καλά βαθμονομημένες (δηλαδή πιο «αιχμηρές» και \en{overconfident} σε λάθη). 

Τέλος, οι παραλλαγές χωρητικότητας (\en{SegResNet 1} έναντι \en{SegResNet 2},
και \en{SegMamba 1} έναντι \en{SegMamba 2}) δείχνουν ότι η «βαρύτερη» ρύθμιση
μπορεί να προσφέρει μικρό αλλά μετρήσιμο κέρδος στην επικάλυψη
(π.χ. \en{SegResNet 1}: $0.8601$ έναντι $0.859$), χωρίς όμως να αλλάζει
δραστικά την κατάταξη. Στις επόμενες ενότητες διερευνάται αν αυτές οι μικρές
διαφορές συνοδεύονται από πιο σταθερή σύγκλιση ή/και πιο καθαρό οπτικό
περίγραμμα στις προβλέψεις.

\section{Καμπύλες εκπαίδευσης και σταθερότητα σύγκλισης}
\label{sec:results_curves}
Στα σχήματα \ref{fig:graphs1}, \ref{fig:graphs2} και \ref{fig:graphs3} παρουσιάζονται οι καμπύλες 
εκπαίδευσης για κάθε αρχιτεκτονική. Πρώτη καμπύλη αποτελεί τη μετρική \en{Dice} και η δεύτερη τα \en{training} και \en{validation losses} κατά τη διάρκεια των \en{epochs}.

\paragraph{Γενική εικόνα σύγκλισης.}
Σε όλες σχεδόν τις \en{CNN}-βασισμένες αρχιτεκτονικές παρατηρείται \textbf{ταχεία αρχική βελτίωση} του \en{validation Dice} στα πρώτα 5-15 \en{epochs},
συγκλίνοντας σχετικά νωρίς (σταδιακή, μικρή βελτίωση) μέχρι το τέλος της εκπαίδευσης. 
Αυτό υποδηλώνει ότι το μοντέλο μαθαίνει γρήγορα τη χονδρική μορφολογία του πλακούντα, ενω οι επιπλέον εποχές συμβάλλουν κυρίως σε λεπτότερη προσαρμογή (όρια, μικρές ασυνέχειες, μείωση \en{false positives}).

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/history_attentionUnet.png}
    \caption{\en{Attention U-Net}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/history_dynunet.png}
    \caption{\en{DynUNet}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/history_SwinUNETR.png}
    \caption{\en{SwinUNETR}}
  \end{subfigure}
  \caption{}
  \label{fig:graphs1}
\end{figure}  

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\linewidth}
    \centering\includegraphics[width=\linewidth]{figures/history_segresLight.png}
    \caption{\en{SegResNet 2 (No of Filters = 32)}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\linewidth}
    \centering\includegraphics[width=\linewidth]{figures/history_segresHeavy.png}
    \caption{\en{SegResNet 1 (No of Filters = 64)}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering\includegraphics[width=\linewidth]{figures/history_UNET.png}
    \caption{\en{U-Net}}
  \end{subfigure}
  \caption{}
  \label{fig:graphs2}
\end{figure}  

  
\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \centering\includegraphics[width=\textwidth]{figures/history_UNETR.png}
    \caption{\en{UNETR}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering\includegraphics[width=\textwidth]{figures/history_segmambaheavy.png}
    \caption{\en{SegMamba 1 (5 layers)}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering\includegraphics[width=\textwidth]{figures/history_segmamba.png}
    \caption{\en{SegMamba 2 (4 layers)}}
  \end{subfigure}
  \caption{}
  \label{fig:graphs3}
\end{figure}  



%______________________ VISUAL PROVLEPSEIS KATW

\section{Ποιοτική αξιολόγηση προβλέψεων}
\label{sec:results_qual}

\begin{Illustration}[!h]
  \centering
  \includegraphics[width=0.68\linewidth]{figures/segmentation_masks_AttentionUnet.png}
  \caption{\en{Attention U-Net}}
\end{Illustration}

\begin{Illustration}[!h]
  \centering
  \includegraphics[width=0.68\linewidth]{figures/segmentation_masks_DynUNet.png}
  \caption{\en{DynUNet}}
\end{Illustration}

\begin{Illustration}[!h]
  \centering
  \includegraphics[width=0.68\linewidth]{figures/segmentation_masks_SwinUNETR.png}
  \caption{\en{SwinUNETR}}
\end{Illustration}


\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_SegResHeavy.png}
  \caption{\en{SegResNet 1 (No of Filters = 64)}}
\end{Illustration}

\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_SegResLight.png}
  \caption{\en{SegResNet 2 (No of Filters = 32)}}
\end{Illustration}

\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_unet.png}
  \caption{\en{U-Net}}
\end{Illustration}




\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_UNETR.png}
  \caption{\en{UNETR}}
\end{Illustration}
\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_segmambaHEAVY.png}
  \caption{\en{SegMamba 1 (5 layers)}}
\end{Illustration}
\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_segmambaLIGHT.png}
  \caption{\en{SegMamba 2 (4 layers)}}
\end{Illustration}





\section{Συζήτηση και ερμηνεία}
 
\label{sec:results_discussion}

