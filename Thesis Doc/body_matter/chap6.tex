\chapter{Αποτελέσματα Πειραματικής Αξιολόγησης}
\label{ch:results}

Στο κεφάλαιο αυτό παρουσιάζονται τα αποτελέσματα της συγκριτικής αξιολόγησης των αρχιτεκτονικών 
τμηματοποίησης με τη δομή που περιγράφηκε στο Κεφάλαιο \ref{ch:experiments}. 
Όλα τα μοντέλα εκπαιδεύτηκαν και αξιολογήθηκαν με \textbf{ενιαίο} πειραματικό πρωτόκολλο 
(προεπεξεργασία, δειγματοληψία, βελτιστοποίηση, επικύρωση), ώστε οι διαφορές στο τέλος να αποδίδονται όσο το δυνατόν περισσότερο στην αρχιτεκτονική και όχι σε ασυνεπείς ρυθμίσεις ή διαδικασίες.

Πρώτα, παρατίθενται τα ποσοτικά αποτελέσματα στα δεδομένα αξιολόγησης μέσω μετρικών επικάλυψης 
(\en{Dice, IoU}) και της τιμής της απώλειας επικύρωσης (\en{validation loss}). 
Έπειτα, συμπληρώνονται με ποιοτική αξιολόγηση μέσω οπτικών προβλέψεων έναντι 
\en{ground truth} (τμηματοποίηση παρεχόμενη απο ειδικούς υγείας), 
και πραγματοποιείται και έλεγχος ως προς τη συμφωνία των ποσοτικών αποτελεσμάτων με τις εικόνες.

Τέλος, παρουσιάζονται και σχετικές δημοσιευμένες εργασίες με όμοιο στόχο,
μαζί με τα τελικά τους αποτελέσματα, ώστε να γίνει μια ενδεικτική (μη αυστηρή)
και πιο ελεύθερη αντιπαραβολή με τα ευρήματα της παρούσας εργασίας.

\section{Παρουσίαση αποτελεσμάτων}
\label{sec:exp_results}
Τα αποτελέσματα παρουσιάζονται σε δύο επίπεδα:
\begin{itemize}
  \item \textbf{Ποσοτικά:} μετρικές \en{Dice/IoU} και απώλειες (\en{train/val loss}), με σύγκριση μεταξύ μοντέλων.
  \item \textbf{Ποιοτικά:} ενδεικτικές οπτικοποιήσεις προβλέψεων/σφαλμάτων
        σε αντιπροσωπευτικά περιστατικά.
\end{itemize}
Ο Πίνακας~\ref{tab:main_results} συνοψίζει τη \textbf{καλύτερη} επίδοση κάθε μοντέλου στο 
\en{validation set}, όπως προέκυψε σε επίπεδο \en{3D} όγκου σε 120 \en{epochs}. 
Οι τιμές \en{Dice} χρησιμοποιούνται ως σημείο αναφοράς για την αναλυτικότερη ποιοτική και συγκριτική συζήτηση που ακολουθεί και αντιστοιχούν στη μέγιστη τιμή του \en{mean Dice} που επιτεύχθηκε σε κάποιο \en{epoch} εντός της εκπαίδευσης.

\begin{table}[!htbp]
\centering
\caption{Αποτελέσματα ανά αρχιτεκτονική στο \en{validation set}.}
\label{tab:main_results}
\begin{tabular}{lccc}
\hline
\textbf{Μοντέλο} & \en{\textbf{Dice}} & \en{\textbf{IoU}} & \en{\textbf{Val Loss}} \\
\hline
\en{U-Net}            & $0.823$  & $0.7002$  & $0.2177$ \\
\en{Attention U-Net}  & $0.851$  & $0.74$  & $0.2034$  \\
\en{DynUNet}          & $0.846$ & $0.7342$  & $0.1897$ \\
\en{UNETR}            & $0.772$  & $0.6345$ & $0.2842$  \\
\en{SwinUNETR Heavier}        & $0.8497$ & $0.7401$ & $0.1838$ \\
\en{SwinUNETR Lighter}        & $0.8490$ & $0.7387$ & $0.1838$ \\
\en{SegResNet Heavier}        & $0.8601$  & $0.7558$ & $0.1678$ \\
\en{SegResNet Lighter}        & $0.859$  & $0.7544$ & $0.1806$ \\
\en{SegMamba Heavier}         & $0.8606$ & $0.7566$ & $0.1685$ \\
\en{SegMamba Lighter}         & $0.8581$ & $0.7526$ & $0.1697$ \\
\hline
\end{tabular}
\end{table}

Σημειώνεται ότι οι μετρικές επικάλυψης αποτυπώνουν κυρίως τη συμφωνία ως προς το εμβαδό/όγκο της πρόβλεψης 
και δεν εγγυώνται πάντα οπτικά σωστά όρια σε όλες τις περιπτώσεις. 

\section{Συνοπτική κατάταξη και κύρια ευρήματα}
\label{sec:results_ranking}
Ξεκινώντας από τον Πίνακα \ref{tab:main_results}, η κατάταξη των μοντέλων 
με βάση τη μέγιστη μέση τιμή του \en{Dice} δείχνει ότι η καλύτερη επίδοση επιτυγχάνεται από το 
\en{SegMamba Heavier} 
(\en{Dice}$=0.8606$) και έπειτα τα \en{SegResNet Heavier} (\en{Dice}$=0.8601$) και 
\en{SegResNet Lighter} (\en{Dice}$=0.859$). 
Οι διαφορές μέσα στα προαναφερθέντα είναι της τάξης του $\approx 0.002$--$0.007$ 
σε \en{Dice}.

Η εικόνα αυτή επιβεβαιώνεται και από τη συμπληρωματική μετρική \en{IoU}:
τα υψηλότερα \en{IoU} παρατηρούνται επίσης στα \en{SegMamba Heavier} ($0.7566$) και
\en{SegResNet Heavier} ($0.7558$), με τα υπόλοιπα μοντέλα της κορυφής να ακολουθούν
πολύ κοντά. Παράλληλα, οι τιμές \en{validation loss} είναι χαμηλότερες για τα
μοντέλα με καλύτερο \en{Dice} (π.χ. \en{SegResNet Heavier}: $0.1678$,
\en{SegMamba Heavier}: $0.1685$), γεγονός που είναι συμβατό με καλύτερη συνολική
βελτιστοποίηση. 
Ωστόσο, επειδή το \en{loss} αποτελεί σύνθετο κριτήριο και δεν
αντιστοιχεί μονοσήμαντα σε μια \en{overlap} μετρική, η τελική κατάταξη
στηρίζεται πρωτίστως στο \en{Dice} (και υποστηρίζεται από \en{IoU}).

Σε επίπεδο οικογενειών αρχιτεκτονικής, παρατηρείται ότι οι αποδοτικές
\en{CNN-based} προσεγγίσεις (\en{SegResNet}) και τα \en{State Space-based}
μοντέλα (\en{SegMamba}) υπερέχουν συνολικά των \en{Transformer-based}
αρχιτεκτονικών σε αυτή τη πειραματική αξιολόγηση. Ειδικότερα, το
\en{UNETR} εμφανίζει τη χαμηλότερη επίδοση (\en{Dice}$=0.772$,
\en{IoU}$=0.6345$), αποτελώντας σαφή
\en{outlier}. 
Αντιθέτως, και οι δύο εκτελέσεις του \en{SwinUNETR} αποδίδουν εξαιρετικά:
\en{SwinUNETR Heavier} (\en{Dice}$=0.8497$, \en{IoU}$=0.7401$) και
\en{SwinUNETR Lighter} (\en{Dice}$=0.8490$, \en{IoU}$=0.7387$), με τη
\en{Lighter} να φτάνει \en{Val Loss}$=0.1838$ στο \en{epoch} 108.
Οι τιμές αυτές απέχουν κατά περίπου $0.01$ σε \en{Dice} από την κορυφή.

Αξίζει να σχολιάσουμε το \en{U-Net} (ο πρωτοπόρος του αντικειμένου) απέδωσε αρκετά καλά με 
\en{Dice Score}$= 0.823$, συμφωνόντας με την τυπική απόδοση σε σχετικές εργασίες όπως θα σχολιαστεί στη συνέχεια.

Τέλος, οι παραλλαγές χωρητικότητας (\en{SegResNet Heavier} έναντι \en{SegResNet Lighter},
\en{SegMamba Heavier} έναντι \en{SegMamba Lighter} και \en{SwinUNETR Heavier}
έναντι \en{SwinUNETR Lighter}) δείχνουν ότι η «βαρύτερη» ρύθμιση προσφέρει
αμελητέο πλεονέκτημα (π.χ. \en{SegResNet Heavier}: $0.8601$ έναντι $0.859$), συνεπώς 
θα πρέπει να αναλογιστεί η επιβάρυνση στο υπολογιστικό κόστος που επιφέρει η 
επιπρόσθετη χωρητικότητα, με την απόδοση που προσφέρεται λόγω αυτής. 

\section{Καμπύλες εκπαίδευσης και σταθερότητα σύγκλισης}
\label{sec:results_curves}
Στα σχήματα \ref{fig:graphs1}, \ref{fig:graphs2} και \ref{fig:graphs3} παρουσιάζονται οι καμπύλες 
εκπαίδευσης για κάθε αρχιτεκτονική. Σε κάθε περίπτωση, 
πρώτη καμπύλη παρουσιάζει τη μετρική \en{Dice} και η δεύτερη τις απώλειες \en{training} και 
\en{validation} κατά τη διάρκεια των \en{epochs}.


\paragraph{Γενική εικόνα σύγκλισης.}
Σε όλες τις \en{CNN}-βασισμένες αρχιτεκτονικές παρατηρείται \textbf{ταχεία αρχική βελτίωση} του \en{validation Dice} στα πρώτα 5-15 \en{epochs},
συγκλίνοντας σχετικά νωρίς, ακολουθούμενη απο σταδιακή βελτίωση μέχρι το τέλος της εκπαίδευσης. 
Αυτό υποδηλώνει ότι το μοντέλο μαθαίνει γρήγορα τη χονδρική μορφολογία του πλακούντα, ενώ οι επιπλέον εποχές συμβάλλουν κυρίως σε λεπτότερη προσαρμογή (όρια, μικρές ασυνέχειες, μείωση \en{false positives}).

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/history_attentionUnet.png}
    \caption{\en{Attention U-Net}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/history_dynunet.png}
    \caption{\en{DynUNet}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/history_SwinUNETR_HEAVIER.png}
    \caption{\en{SwinUNETR Heavier}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/history_SwinUNETR_LIGHTER.png}
    \caption{\en{SwinUNETR Lighter}}
  \end{subfigure}
  \caption{Καμπύλες εκπαίδευσης: \en{Validation Dice} (πάνω) και \en{training/validation loss} (κάτω) για \en{Attention U-Net}, \en{DynUNet}, \en{SwinUNETR Heavier} και \en{SwinUNETR Lighter}. Το αστέρι και η κατακόρυφη διακεκομμένη γραμμή δείχνουν το \en{epoch} του καλύτερου \en{Dice}.}
  \label{fig:graphs1}
\end{figure}  

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\linewidth}
    \centering\includegraphics[width=\linewidth]{figures/history_segresLight.png}
    \caption{\en{SegResNet Lighter (No of Filters = 32)}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\linewidth}
    \centering\includegraphics[width=\linewidth]{figures/history_segresHeavy.png}
    \caption{\en{SegResNet Heavier (No of Filters = 64)}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering\includegraphics[width=\linewidth]{figures/history_UNET.png}
    \caption{\en{U-Net}}
  \end{subfigure}
  \caption{Καμπύλες εκπαίδευσης: \en{Validation Dice} (πάνω) και \en{training/validation loss} (κάτω) για \en{SegResNet Lighter}, \en{SegResNet Heavier} και \en{U-Net}. Το αστέρι και η κατακόρυφη διακεκομμένη γραμμή δείχνουν το \en{epoch} του καλύτερου \en{Dice}.}
  \label{fig:graphs2}
\end{figure}  

  
\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \centering\includegraphics[width=\textwidth]{figures/history_UNETR.png}
    \caption{\en{UNETR}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering\includegraphics[width=\textwidth]{figures/history_segmambaheavy.png}
    \caption{\en{SegMamba Heavier (5 layers)}}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering\includegraphics[width=\textwidth]{figures/history_segmamba.png}
    \caption{\en{SegMamba Lighter (4 layers)}}
  \end{subfigure}
  \caption{Καμπύλες εκπαίδευσης: \en{Validation Dice} (πάνω) και \en{training/validation loss} (κάτω) για \en{UNETR}, \en{SegMamba Heavier} και \en{SegMamba Lighter}. Το αστέρι και η κατακόρυφη διακεκομμένη γραμμή δείχνουν το \en{epoch} του καλύτερου \en{Dice}.}
  \label{fig:graphs3}
\end{figure}  

\paragraph{Συγκριτική ερμηνεία καμπυλών.}
Όλες οι προσωμοιώσεις εμφανίζουν απότομη άνοδο του
\en{validation Dice} στα πρώτα $\sim$10--20 \en{epochs} και στη συνέχεια
σταθεροποίηση (\en{plateau}). Επίσης, όλες οι καμπύλες είναι σχεδόν πανομοιότυπες σε μορφή, 
κάτι που αναμένοταν δεδομένου ότι το πειραματικό πλαίσιο ήταν κοινό για όλες τις προσωμοιώσεις. 
Ομοίως, οι παραλλαγές \en{SegMamba} συγκλίνουν γρήγορα σε υψηλές τιμές \en{Dice} και
παραμένουν σταθερά στην κορυφή.

\paragraph{\en{Transformer-based} συμπεριφορά.}
Το \en{UNETR} λειτουργεί ως \en{outlier}, επιτυγχάνοντας χαμηλότερο \en{best Dice},
γεγονός που συμφωνεί με τη συνολική του υστέρηση στον Πίνακα~\ref{tab:main_results}.
Αντίθετα, και οι δύο διαμορφώσεις \en{SwinUNETR Heavier/Lighter} παρουσιάζουν
πιο ομαλή και σταδιακή βελτίωση και, ενώ δεν ξεπερνούν την κορυφή
(\en{SegResNet}/\en{SegMamba}), αποδίδουν καλύτερα απο το απλό \en{UNETR}. 
Η \en{Lighter} εκδοχή φτάνει \en{Dice}$=0.8490$, \en{IoU}$=0.7387$ και
\en{Val Loss}$=0.1838$ στο \en{epoch} 108, πολύ κοντά στη \en{Heavier}.
Το αποτέλεσμα είναι ενδεικτικό ότι η
ιεραρχική προσοχή με τοπικά παράθυρα του \en{Swin} είναι πιο κατάλληλη από έναν \en{ViT-style encoder} \cite{hatamizadeh2022swinunetr} σε προβλήματα με όμοιες συνθήκες.

\paragraph{Σταθερότητα και γενίκευση.}
Οι καμπύλες \en{training} και \en{validation loss} μειώνονται παράλληλα και
δεν παρατηρείται έντονη απόκλιση που να υποδεικνύει ισχυρή υπερπροσαρμο\-γή στο
εξεταζόμενο εύρος \en{epochs}. Το καλύτερο \en{checkpoint} ορίζεται ως το
\en{epoch} μέγιστου \en{validation Dice} (κατακόρυφη γραμμή στα
γραφήματα), το οποίο εμφανίζεται συνήθως σε μεταγενέστερο \en{epoch}, ενώ οι
μεγαλύτερες βελτιώσεις έχουν ήδη πραγματοποιηθεί νωρίτερα.

\paragraph{Σύνδεση με ποιοτική αξιολόγηση.}
Στην επόμενη ενότητα εξετάζονται οπτικά παραδείγματα προβλέψεων και τυπικών
σφαλμάτων, ώστε να αξιολογηθεί κατά πόσο οι διαφορές στο \en{Dice/IoU}
αντιστοιχούν σε ουσιαστικές διαφορές στην ποιότητα ορίων.

\FloatBarrier

%______________________ VISUAL PROVLEPSEIS KATW

\section{Ποιοτική αξιολόγηση προβλέψεων}
\label{sec:results_qual}

Η ποιοτική αξιολόγηση συμπληρώνει τις ποσοτικές μετρικές του Πίνακα
\ref{tab:main_results}, καθώς οι μετρικές επικάλυψης (\en{Dice/IoU})
αποτυπώνουν κυρίως τη συμφωνία ως προς τον όγκο και δεν εγγυώνται πάντα
αντίστοιχη ακρίβεια στα όρια ή στα λεπτά τμήματα της δομής. Στα σχήματα \ref{ill1} έως \ref{ill10} 
που ακολουθούν παρουσιάζονται \textbf{ενδεικτικές τομές} από δύο περιστατικά
(\en{Sample 1/2}) και η σύγκριση: \en{MRI slice} (αριστερά), \en{ground truth}
μάσκα (κέντρο) και η πρόβλεψη που επετεύχθει απο το μοντέλο (δεξιά). Ο πλακούντας και η πρόβλεψη 
απεικονίζονται με πράσινο και το υπόβαθρο με κόκκινο.

Κατά την οπτική επιθεώρηση εξετάζονται κυρίως:
\begin{itemize}
  \item \textbf{Υπο- ή υπερ-τμηματοποίηση},
  \item \textbf{συνέχεια/συνοχή} της μάσκας,
  \item \textbf{ψευδοθετικά} (\en{false positives}) ως απομονωμένες περιοχές,
  \item \textbf{ποιότητα ορίων} (ομαλότητα και μορφολογική συνέπεια).
\end{itemize}

\paragraph{Συμφωνία ποιοτικών και ποσοτικών αποτελεσμάτων.}
Σε γενικές γραμμές, η οπτική εικόνα επιβεβαιώνει την κατάταξη της
Ενότητας \ref{sec:results_ranking}. Τα μοντέλα με την υψηλότερη επίδοση σε
\en{Dice/IoU} παράγουν πιο συνεπείς και
``καθαρές'' μάσκες, με όρια που ακολουθούν καλύτερα τη μορφολογία του
πλακούντα και με ελάχιστα ψευδοθετικά. Αντίθετα, το \en{UNETR}, που είναι
ποσοτικά ο ασθενέστερος \en{outlier}, εμφανίζει ορατές αστοχίες (ανομοιόμορφα
περιγράμματα, τμηματοποιήσεις εκτός στόχου και μικρές απομονωμένες περιοχές),
οι οποίες εξηγούν τη χαμηλή του \en{IoU} και το υψηλότερο \en{validation loss}.

\paragraph{\en{CNN-based} μοντέλα.}
Τα \en{U-Net}, \en{Attention U-Net} και \en{DynUNet} αποδίδουν γενικά σωστή
γεωμετρία και συνεχείς μάσκες, με αποκλίσεις που εμφανίζονται κυρίως στα άκρα
και σε λεπτές περιοχές (ελαφρά υπο- ή υπερ-τμηματοποίηση). Η \en{Attention U-Net}
και το \en{DynUNet} δείχνουν πιο σταθερή συμπεριφορά από το βασικό \en{U-Net},
συμβατό με το μικρό αλλά μετρήσιμο κέρδος στις μετρικές
(\en{Dice}$\approx 0.851$ έναντι $0.823$). Παράλληλα, το \en{U-Net} παρότι
παρουσιάζει αποδεκτή επικάλυψη, εμφανίζει μεγαλύτερο \en{validation loss}
(Πίνακας \ref{tab:main_results}), κάτι που είναι ενδεικτικό ότι το \en{loss}
(\en{Dice + CE}) είναι πιο ευαίσθητο σε αβεβαιότητα/λάθη κοντά στα όρια,
ακόμη και όταν η τελική δυαδική μάσκα (μετά το \en{thresholding}) είναι οπτικά
ικανοποιητική.

\paragraph{\en{Transformer-based} μοντέλα.}
Τα \en{SwinUNETR Heavier/Lighter} παράγουν συνεπείς προβλέψεις με καλό
περιορισμό των ψευδοθετικών, κάτι που συμφωνεί με το ότι αποτελούν τις
καλύτερες \en{Transformer-based} διαμορφώσεις της σύγκρισης
(\en{Dice}$=0.8497/0.8490$, \en{IoU}$=0.7401/0.7387$). Η διαφορά τους είναι
πολύ μικρή, με τη \en{Lighter} εκδοχή να διατηρεί \en{Val Loss}$=0.1838$
στο \en{epoch} 108. Ωστόσο, σε ορισμένα σημεία η πρόβλεψη είναι πιο
``συντηρητική'' (ελαφρά υπο-τμηματοποίηση σε λεπτές προεξοχές), γεγονός που
μπορεί να συμβάλλει στη διαφορά $\sim 0.01$ σε \en{Dice} από την κορυφή.
Αντίθετα, το \en{UNETR} εμφανίζει πιο ασταθή
συμπεριφορά, με εμφανή \en{false positives} και ανομοιόμορφα περιγράμματα, τα
οποία υποβαθμίζουν τόσο την \en{IoU} όσο και την αντιληπτή ποιότητα ορίων.

\paragraph{Μοντέλα κορυφής: \en{SegResNet} και \en{SegMamba}.}
Τα \en{SegResNet} και \en{SegMamba} δίνουν, στις ενδεικτικές περιπτώσεις,
προβλέψεις πολύ κοντά στο \en{ground truth}: η μάσκα είναι συνεχής (χωρίς
``τρύπες'') και τα όρια ακολουθούν πιο πιστά τη μορφολογία. Οι διαφορές μεταξύ
``βαριάς'' και ``ελαφριάς'' παραλλαγής είναι μικρές και συμφωνούν με τις
αντίστοιχα μικρές διαφορές στις μετρικές (\en{Dice} στην τρίτη δεκαδική).

\paragraph{Περιορισμοί της οπτικής σύγκρισης.}
Οι απεικονίσεις αφορούν μεμονωμένες \en{2D} τομές, ενώ οι μετρικές
υπολογίζονται σε \en{3D} όγκους. Επομένως, μικρές τοπικές αποκλίσεις μπορεί να
μην είναι αντιπροσωπευτικές για το σύνολο του όγκου, αλλά παραμένουν χρήσιμες
για την κατανόηση τυπικών σφαλμάτων και την ερμηνεία των ποσοτικών δεικτών.

\begin{Illustration}[!h]
  \centering
  \includegraphics[width=0.68\linewidth]{figures/segmentation_masks_AttentionUnet.png}
  \caption{\en{Attention U-Net}}
  \label{ill1}
\end{Illustration}

\begin{Illustration}[!h]
  \centering
  \includegraphics[width=0.68\linewidth]{figures/segmentation_masks_DynUNet.png}
  \caption{\en{DynUNet}}
  \label{ill2}
\end{Illustration}

\begin{Illustration}[!h]
  \centering
  \includegraphics[width=0.68\linewidth]{figures/segmentation_masks_SwinUNETR_HEAVIER.png}
  \caption{\en{SwinUNETR Heavier}}
  \label{ill3}
\end{Illustration}

\begin{Illustration}[!h]
  \centering
  \includegraphics[width=0.68\linewidth]{figures/segmentation_masks_SwinUNETRlighter.png}
  \caption{\en{SwinUNETR Lighter}}
  \label{ill10}
\end{Illustration}


\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_SegResHeavy.png}
  \caption{\en{SegResNet Heavier (No of Filters = 64)}}
  \label{ill4}
\end{Illustration}

\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_SegResLight.png}
  \caption{\en{SegResNet Lighter (No of Filters = 32)}}
  \label{ill5}
\end{Illustration}

\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_unet.png}
  \caption{\en{U-Net}}
  \label{ill6}
\end{Illustration}




\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_UNETR.png}
  \caption{\en{UNETR}}
  \label{ill7}
\end{Illustration}
\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_segmambaHEAVY.png}
  \caption{\en{SegMamba Heavier (5 layers)}}
  \label{ill8}
\end{Illustration}
\begin{Illustration}[!h]
  \centering\includegraphics[width=0.68\linewidth]{figures/segmentation_masks_segmambaLIGHT.png}
  \caption{\en{SegMamba Lighter (4 layers)}}
  \label{ill9}
\end{Illustration}





\FloatBarrier

\section{Σύγκριση με δημοσιευμένα αποτελέσματα}
\label{sec:results_literature_compare}

Για να τοποθετηθούν τα ευρήματα της παρούσας εργασίας σε ευρύτερο πλαίσιο,
παρατίθεται στον Πίνακα~\ref{tab:literature_comparison} συνοπτική σύγκριση με
σχετικές μελέτες τμηματοποίησης πλακούντα σε \en{MRI}
\cite{shahedi2021placenta,shahedi2022automatic,liu2023evaluation,huang2023prenatal,lee2023mrfmas,saito2025planets}.

\begin{table}[!htbp]
\centering
\scriptsize
\setlength{\tabcolsep}{2.5pt}
\renewcommand{\arraystretch}{1.12}
\caption{Σύνοψη αποτελεσμάτων από σχετικές μελέτες τμηματοποίησης πλακούντα σε \en{MRI}.}
\label{tab:literature_comparison}
\begin{tabular}{p{3.0cm}p{2.0cm}p{3.5cm}p{4.0cm}p{4.0cm}}
\hline
\textbf{Μελέτη} & \textbf{Μοντέλο} & \textbf{Δεδομένα / \en{split}} & \textbf{Μετρική πλακούντα} & \textbf{Σχόλιο} \\
\hline
\en{Shahedi et al.} 2022 \cite{shahedi2022automatic}
& \en{CNN--based}
& 181 \en{total} (\en{train}=157, \en{val}=24) + \en{test}=60
& \en{DSC}=0.80
& Μητρική κοιλότητα: \en{DSC}=0.92. \\

\en{Shahedi et al.} 2021 \cite{shahedi2021placenta}
& Δύο \en{CNN--based}
& 70 \en{total}, έλεγχος σε 20 (\en{normal}) και 50 (\en{\-normal+PAS})
& \en{DSC}=0.82 (\en{\-normal}), 0.83 (\en{+PAS})
& Μητρική κοιλότητα: \en{DSC}=0.92 και 0.88 αντίστοιχα. \\ 


\en{Liu et al.} 2023 \cite{liu2023evaluation}
& \en{SADL}
& 154 \en{total}, \en{train}=108, \en{val}=15, \en{test}=31
& \en{DSC}=0.83$\pm$0.06, 0.84$\pm$0.05 
& \en{UNet achieved}: ($0.77, 0.76$). \\

\en{Huang et al.} 2023 \cite{huang2023prenatal}
& \en{CNN-based} 
& 241 (\en{axial}), και 101 (\en{sagittal\-}) \en{MRI}
& \en{DSC}=0.82 (\en{axial}), 0.82 (\en{sagittal})
& Μητρική κοιλότητα: \en{DSC}=0.87 (\en{axial}), 0.92 (\en{sagittal}). \\

\en{Lee et al.} 2023 \cite{lee2023mrfmas}
& \en{MRF--MAS vs UNet}
& 390 \en{total}, \en{train}=312, \en{test}=78
& \en{Dice}=0.8992 (\en{MRF-MAS}), \en{U-Net Dice}=0.8632
& Αναφορά και \en{IoU}=0.8169 για το προτεινόμενο μοντέλο. \\

\en{Saito et al.} 2025 \cite{saito2025planets}
& \en{PlaNet-S (UNet+SegNeXt)}
& 1090 \en{total}, 875 \en{train}-215 \en{test}
& \en{IoU}=0.78$\pm$0.10 (\en{PlaNet-S})
& \en{U-Net IoU}=0.73$\pm$0.13, \en{DS-transUNet IoU}=0.64$\pm$0.16. \\

\textbf{Παρούσα εργασία} 
& \en{UNet}
& 137 περιπτώσεις, \en{train}=109, \en{val}=28
& \en{Dice}=0.823, \en{IoU}=0.7002 
& Ενιαίο πρωτόκολλο σε 10 διαμορφώσεις μοντέλων και αξιολόγηση σε \en{3D} όγκους. 
\\

\textbf{Παρούσα εργασία} 
& \en{SegMamba Heavier}
& 
& \en{Dice}=0.8606, \en{IoU}=0.7566
& Απέδωσε καλύτερα απο τις άλλες διαμορφώσεις \\


\hline
\end{tabular}
\end{table}

Η παραπάνω σύγκριση είναι \textbf{ενδεικτική} και όχι αυστηρά αντικειμενική
, επειδή τα πειράματα δεν έχουν εκτελεστεί σε κοινό σύνολο
δεδομένων ή ενιαίο πρωτόκολλο. 
Παρά τα παραπάνω, οι τιμές επικάλυψης της παρούσας εργασίας
(\en{Dice}$=0.8606$, \en{IoU}$=0.7566$) κινούνται στο ίδιο εύρος με τη
σύγχρονη βιβλιογραφία για τμηματοποίηση πλακούντα σε \en{MRI}, κάτι που
υποστηρίζει τη συνολική εγκυρότητα της πειραματικής μεθοδολογίας.

\section{Συζήτηση και ερμηνεία}
 
\label{sec:results_discussion}

Στην ενότητα αυτή συντίθενται τα ποσοτικά ευρήματα (Πίνακας~\ref{tab:main_results}
και καμπύλες εκπαίδευσης) με την ποιοτική επιθεώρηση (Ενότητα~\ref{sec:results_qual}),
με στόχο να δοθεί συνεκτική ερμηνεία των διαφορών μεταξύ των αρχιτεκτονικών και
να αποσαφηνιστεί ποια συμπεράσματα είναι σταθερά, αλλά και ποιοι παράγοντες
επηρεάζουν την αξιοπιστία/γενίκευση των αποτελεσμάτων.

\paragraph{Σύνοψη επιδόσεων και κλίμακα διαφορών.}
Η συνολική εικόνα δείχνει ότι οι καλύτερες επιδόσεις στο \en{validation set}
συγκεντρώνονται σε μια ``ομάδα κορυφής'' γύρω από \en{Dice} $0.86$:
\en{SegMamba Heavier} (\en{Dice}$=0.8606$) και \en{SegResNet Heavier/Lighter}
(\en{Dice}$=0.8601/0.859$), με πολύ μικρές μεταξύ τους διαφορές
(περίπου $0.002$--$0.003$). Το \en{SwinUNETR Heavier/Lighter}
(\en{Dice}$=0.8497/0.8490$) είναι
ανταγωνιστικό, αλλά παραμένει χαμηλότερα από την κορυφή κατά περίπου $0.01$ σε
\en{Dice}, αλλά κάτα $0.02$ παραπάνω απο το \en{base UNet}, 
ενώ το \en{UNETR} αποτελεί σαφή \en{outlier} με αισθητά χαμηλότερη
επικάλυψη (\en{Dice}$=0.772$). Η μικρή απόσταση εντός της κορυφής υποδηλώνει
ότι, για το συγκεκριμένο σύνολο δεδομένων και πρωτόκολλο, η επίδοση τείνει να
κορεστεί: περαιτέρω βελτιώσεις αναμένονται να είναι οριακές και πιθανόν να
εξαρτώνται περισσότερο από λεπτομέρειες \en{pre-processing}, δειγματοληψίας
\en{patches} ή ποιότητας επισημειώσεων, παρά από ριζικά διαφορετική
αρχιτεκτονική.

\paragraph{Ερμηνεία υπεροχής \en{CNN}/\en{SSM} προσεγγίσεων.}
Τα αποτελέσματα υποδεικνύουν ότι οι \en{CNN}-βασισμένες λύσεις
(\en{SegResNet}, \en{DynUNet}, \en{Attention U-Net}) και τα \en{SSM-based}
μοντέλα (\en{SegMamba}) είναι ιδιαίτερα κατάλληλα για τμηματοποίηση πλακούντα
σε \en{3D MRI}. Μια εύλογη ερμηνεία είναι ότι το πρόβλημα κυριαρχείται από
τοπική μορφολογία και συνέπεια ορίων, όπου ο \en{inductive bias} των συνελίξεων και 
η αποδοτική μοντελοποίηση εξαρτήσεων των \en{SSM} αρκούν για να
ανακτηθεί το απαραίτητο \en{context}, χωρίς \en{self-attention} σε όλο τον όγκο. Η ποιοτική
αξιολόγηση συμφωνεί με το παραπάνω: 
τα μοντέλα κορυφής εμφανίζουν πιο συνεκτικές
μάσκες και περιορισμένα \en{false positives}, με όρια που ακολουθούν καλύτερα τη
μορφολογία του \en{ground truth}.

\paragraph{Σχόλια για \en{Transformer} μοντέλα: \en{UNETR} έναντι \en{SwinUNETR}.}
Η αισθητά χαμηλότερη επίδοση του \en{UNETR} είναι συμβατή με τη γενικότερη
παρατήρηση ότι \en{ViT}-τύπου \en{encoders} τείνουν να απαιτούν μεγαλύτερο
όγκο δεδομένων, προσεκτικότερο \en{regularization} και/ή πιο πλούσια
προεκπαίδευση, ώστε να αποδώσουν ανταγωνιστικά σε ιατρική τμηματοποίηση.
Αντίθετα, το \en{SwinUNETR} εμφανίζει πιο σταθερή και καλύτερη συμπεριφορά,
πιθανώς επειδή ενσωματώνει ισχυρότερη τοπικότητα (ιεραρχικά \en{windows} και
\en{patch merging}), κάτι που λειτουργεί ως πιο κατάλληλος \en{prior} για
\en{3D} δεδομένα με περιορισμένο αριθμό περιπτώσεων. Οπτικά, αυτό αποτυπώνεται
σε πιο ``καθαρά'' όρια και σε περιορισμό των σποραδικών ψευδοθετικών περιοχών,
σε σύγκριση με το \en{UNETR}. Επιπλέον, οι δύο διαμορφώσεις
\en{SwinUNETR Heavier/Lighter} έχουν πρακτικά ισοδύναμη επίδοση
(\en{Dice}$=0.8497/0.8490$), άρα η μείωση χωρητικότητας δεν επιφέρει ουσιαστική
ποιοτική υποβάθμιση.

\paragraph{Σχέση \en{Dice/IoU} και \en{validation loss}.}
Παρότι το \en{validation loss} ακολουθεί γενικά την κατάταξη των μοντέλων, δεν
είναι πλήρως μονοσήμαντο ως προς τις μετρικές επικάλυψης. Η περίπτωση του
\en{U-Net} (ικανοποιητικό \en{Dice} αλλά υψηλότερο \en{loss}) υποδηλώνει ότι ο
συνδυα\-σμός \en{Dice + CE} επηρεάζεται από τη βαθμονόμηση της εξόδου και από
λάθη κοντά στα όρια που μπορεί να μην αλλάζουν δραστικά το τελικό \en{overlap}
μετά το \en{thresholding}. Έτσι, οι μετρικές επικάλυψης πρέπει να ερμηνεύονται
συμπληρωματικά με το \en{loss} και, ιδανικά, με \en{boundary}-ευαίσθητες
μετρικές όταν το ζητούμενο είναι ακριβής εντοπισμός ορίων.

\paragraph{Ακρίβεια έναντι υπολογιστικού κόστους.}
\label{par:costvacc}
Οι παραλλαγές χωρητικότητας (\en{SegResNet Heavier} έναντι \en{SegResNet Lighter} και
\en{SegMamba Heavier} έναντι \en{SegMamba Lighter} και \en{SwinUNETR Heavier}
έναντι \en{SwinUNETR Lighter}) προσφέρουν μόνο μικρό κέρδος στην
επικάλυψη. Αυτό πρακτικά σημαίνει ότι, σε περιβάλλοντα με περιορισμένους πόρους
(\en{VRAM}/χρόνος), μια ελαφρύτερη διαμόρφωση μπορεί να αποτελεί ελκυστική
επιλογή, χωρίς σημαντική θυσία ακρίβειας. 
Επίσης, παρότι το \en{SwinUNETR} (και στις δύο εκδοχές) επιτυγχάνει
ανταγωνιστική επίδοση (σε \en{Dice}) και 
βρίσκεται πολύ κοντά στα κορυφαία \en{CNN-based} μοντέλα, η επί\-τευξη αυτής της επίδοσης συνοδεύεται από σημαντικά αυξημένο υπολογιστικό κόστος. 
Η \en{Transformer-based} δομή του σε \en{3D patches} και ιεραρχικό \en{patch merging} 
οδηγεί σε μεγαλύ\-τερο χρόνο άνα εποχή και αυξημένες απαιτήσεις μνήμης σε σύγκριση με αποδοτικότερες 
\en{CNN} επιλογές όπως το \en{SegResNet} ή ακόμα το \en{DynUNet}. 
Συνεπώς, το \en{SwinUNETR} αποτελεί ισχυρή επιλογή απο πλευράς απόδοσης, αλλά 
έχοντας το υπολογιστικό κόστος υπόψιν, οι εναλλακτικές καθίστανται προτιμότερες.

\subsection{Ενδεικτικοί χρόνοι ολοκλήρωσης εκτέλεσης \en{notebooks}}
\label{subsec:runtime_notebooks}
Για να αποτυπωθεί πρακτικά το κόστος εκτέλεσης, καταγράφηκε ο συνολικός
\en{wall-clock} χρόνος μέχρι την ολοκλήρωση κάθε \en{run} στο \en{cloud}
περιβάλλον εκπαίδευσης. Στον Πίνακα~\ref{tab:runtime_results} παρατίθενται οι
αντίστοιχοι χρόνοι, μαζί με τον επιπλέον χρόνο φόρτωσης \en{Mamba} για τις δύο
εκτελέσεις \en{SegMamba}.

\begin{table}[!htbp]
\centering
\caption{Ενδεικτικοί χρόνοι ολοκλήρωσης ανά \en{run}.}
\label{tab:runtime_results}
\begin{tabular}{lcc}
\hline
\textbf{Μοντέλο} & \textbf{Συνολικός χρόνος} & \textbf{Χρόνος φόρτωσης \en{Mamba}} \\
\hline
\en{SegMamba Lighter} & 05:07:21 & 01:14:47 \\
\en{SegMamba Heavier} & 05:01:31 & 01:13:02 \\
\en{U-Net} & 00:46:01 & -- \\
\en{UNETR} & 02:53:41 & -- \\
\en{SwinUNETR Heavier} & 08:42:00 & -- \\
\en{SwinUNETR Lighter} & 06:00:00 & -- \\
\en{SegResNet Lighter} & 04:28:34 & -- \\
\en{SegResNet Heavier} & 09:46:43 & -- \\
\en{DynUNet} & 02:52:00 & -- \\
\en{Attention U-Net} & 01:37:13 & -- \\
\hline
\end{tabular}
\end{table}

Οι παραπάνω χρόνοι \textbf{δεν αποτελούν επίσημο \en{benchmark}} απόδοσης.
Παρότι οι εκτελέσεις έγιναν με τον ίδιο τύπο \en{GPU} στο \en{cloud} (άρα χωρίς
άμεση επίδραση του τοπικού δικτύου), υπάρχουν πολλοί παράγοντες που δεν είναι
πάντα σταθεροί και επηρεάζουν τον συνολικό χρόνο. Επομένως, οι τιμές χρησιμοποιούνται ως
\textbf{ενδεικτική αναφορά σχετικής ταχύτητας} και χρόνου ολοκλήρωσης των ίδιων
εργασιών μεταξύ μοντέλων.

Η μεγάλη διαφορά στον χρόνο εκτέλεσης σε σχέση με την μικρή απόκλιση στην τελική εικόνα και ολική 
απόδοση μεταξύ των παραλλαγών του \en{SegResNet} αναδεικνύει 
το μικρό του κέρδος εις βάρος παραπάνω απο διπλάσιου χρόνου εκτέλεσης. 
Σε μικρότερο βαθμό το ίδιο ισχύει και για τις παραλλαγές του \en{SwinUNETR}.


\paragraph{Περιορισμοί και παράγοντες γενίκευσης.}
Με τα παραπάνω συμπεράσματα πρέπει να μη ξεχνάμε και τα ακόλουθα: 
\begin{itemize}
  \item οι μετρικές προέρχονται από ένα \en{validation split} και όχι από ανεξάρτητο \en{test set} ή \en{cross-validation},
  \item οι ποιοτικές απεικονίσεις βασίζονται σε μεμονωμένες \en{2D} τομές, ενώ η αξιολόγηση είναι \en{3D}, 
\end{itemize}
Παρόλα αυτά, επειδή όλες οι αρχιτεκτονικές αξιολογούνται με κοινό πρωτόκολλο,
τα συγκριτικά συμπεράσματα (η σχετική κατάταξη και τα τυπικά σφάλματα) είναι
ισχυρότερα από την απόλυτη τιμή της επίδοσης.

\paragraph{Σύνοψη ενότητας.}
Η παρούσα ενότητα αποσαφήνισε τη σχετική συμπεριφορά των αρχιτεκτονικών,
συνδυάζοντας ποσοτικά και ποιοτικά ευρήματα υπό κοινό πρωτόκολλο. Η τελική
σύνθεση των συμπερασμάτων της εργασίας και η συστηματική διατύπωση των
μελλοντικών επεκτάσεων παρουσιάζονται στο επόμενο κεφάλαιο.
