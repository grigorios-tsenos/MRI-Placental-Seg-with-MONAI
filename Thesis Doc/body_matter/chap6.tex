\chapter{Ανάλυση Αποτελεσμάτων και Συζήτηση}
\label{ch:discussion}

Στο κεφάλαιο αυτό αναλύονται και ερμηνεύονται τα αποτελέσματα του
Κεφαλαίου~\ref{ch:experiments}, με στόχο να αποτυπωθούν:
(α) οι κύριες τάσεις απόδοσης ανά αρχιτεκτονική,
(β) η σταθερότητα σύγκλισης και η ευαισθησία σε υπερπαραμέτρους,
(γ) τα συνηθέστερα σφάλματα τμηματοποίησης και οι πιθανές αιτίες τους,
και (δ) οι πρακτικοί συμβιβασμοί κόστους (χρόνος/μνήμη) έναντι ακρίβειας.

Η συζήτηση βασίζεται στις καταγεγραμμένες μετρικές και στα \en{logs} των
\en{runs}, στις καμπύλες \en{train/val loss}, καθώς και σε ποιοτική
επιθεώρηση προβλέψεων σε αντιπροσωπευτικά \en{cases}.
Για γενικό πλαίσιο αξιολόγησης \en{deep learning} στην ιατρική απεικόνιση
και πρακτικές σύγκρισης μοντέλων, λαμβάνονται υπόψη οι κατευθύνσεις της
βιβλιογραφίας \cite{litjens2017survey}.

\section{Συνοπτική κατάταξη μοντέλων και κύρια ευρήματα}
\label{sec:disc_ranking}

Ξεκινώντας από τον Πίνακα~\ref{tab:main_results}, συγκρίνουμε τις
αρχιτεκτονικές ως προς τη μέση επίδοση στο \en{validation set}.
Η κύρια μετρική αναφοράς είναι η επικάλυψη τύπου \en{Dice}-based (και
συμπληρωματικά \en{IoU}-τύπου), καθώς είναι ιδιαίτερα κατάλληλες σε
προβλήματα με αραιό \en{foreground} και έντονη ανισορροπία κλάσεων.
Η βιβλιογραφία υπογραμμίζει ότι σε τέτοιες ρυθμίσεις απαιτείται προσοχή
στην ερμηνεία των μετρικών και στην αναφορά αποτυχιών ανά περίπτωση
(\en{per-case failures}) \cite{litjens2017survey,morgese2024imbalance}.

Ειδικά σε \en{severely imbalanced} σενάρια (όπου ο \en{background} κυριαρχεί),
η σύγκλιση και η συμπεριφορά των \en{false positives/false negatives}
μπορούν να επηρεαστούν σημαντικά από τη στρατηγική δειγματοληψίας
\en{patches} και την επιλογή \en{loss}.
Στο πλαίσιο αυτό, απώλειες και μετρικές βασισμένες σε \en{Dice} έχουν
αναδειχθεί ως πρακτικές επιλογές για μη ισορροπημένες τμηματοποιήσεις
\cite{sudre2017gdl}.

\paragraph{Τι να γράψεις εδώ (με 2--3 παραγράφους).}
\begin{itemize}
  \item Ποιο μοντέλο έχει την καλύτερη μέση επίδοση και αν αυτό
        επιβεβαιώνεται και στη συμπληρωματική μετρική.
  \item Αν υπάρχουν «κοντινά» μοντέλα, σχολίασε με βάση τη σταθερότητα
        (π.\,χ. διακύμανση ανά \en{case}, ευαισθησία στο κατώφλι).
  \item Αν κάποιο μοντέλο έχει καλή μέση τιμή αλλά εμφανίζει αποτυχίες σε
        λίγες περιπτώσεις, ανέφερέ το ρητά (θα τεκμηριωθεί στην ενότητα
        ποιοτικής ανάλυσης).
\end{itemize}

\section{Σταθερότητα εκπαίδευσης και σύγκλιση}
\label{sec:disc_convergence}

Η συμπεριφορά σύγκλισης αποτιμάται από:
(α) τις καμπύλες \en{train/val loss},
(β) την εξέλιξη της επίδοσης στο \en{validation},
και (γ) την απόσταση μεταξύ \en{train} και \en{val} επίδοσης ως ένδειξη
\en{overfitting}.

Στο πειραματικό πλαίσιο χρησιμοποιήθηκε \en{AdamW} \cite{loshchilov2019adamw},
ενώ ο ρυθμός μάθησης μεταβλήθηκε με \en{CyclicLR} (υλοποίηση \en{PyTorch})
\cite{lr_schedulers}. Για την υλοποίηση των πειραμάτων και τη διατήρηση
κοινού \en{pipeline} μετασχηματισμών/αξιολόγησης αξιοποιήθηκε
\en{MONAI} \cite{cardoso2022monai,monai_docs,monai_github}.

\paragraph{Προτεινόμενα σχήματα.}
\begin{itemize}
  \item \textbf{Σχήμα 6.1:} \en{train/val loss} ανά \en{epoch}
        (ένα γράφημα ανά μοντέλο ή ομαδοποίηση 2--3 μοντέλων).
  \item \textbf{Σχήμα 6.2:} επίδοση στο \en{validation} ανά \en{epoch}.
  \item \textbf{Σχήμα 6.3:} \en{learning rate} ανά \en{epoch/step}
        (ώστε να τεκμηριώνεται ο \en{cyclical scheduler}).
\end{itemize}

Στην πράξη, τα μοντέλα μπορεί να διαφοροποιούνται ως προς:
(α) την ταχύτητα σταθεροποίησης, (β) την ευαισθησία σε υπερπαραμέτρους
(π.\,χ. \en{feature size}, \en{window size}), και (γ) την τάση
\en{overfitting} όταν το \en{capacity} είναι υψηλό σε σχέση με το διαθέσιμο
σύνολο δεδομένων.

\section{Επίδραση κατωφλίου και μετα-επεξεργασίας}
\label{sec:disc_threshold}

Η δυαδικοποίηση της εξόδου (\en{sigmoid}) απαιτεί επιλογή κατωφλίου $t$.
Παρότι το $t=0.5$ αποτελεί τυπική αρχική τιμή, στο παρόν πλαίσιο
εφαρμόστηκε περιοδική αναζήτηση σε πλέγμα τιμών (\en{threshold sweep}) και
υιοθέτηση του βέλτιστου ως προς την επίδοση στο \en{validation}.
Η διαδικασία αυτή είναι ιδιαίτερα χρήσιμη όταν η ανισορροπία κλάσεων
οδηγεί σε ασύμμετρη «ποινή» μεταξύ \en{false positives} και
\en{false negatives} \cite{morgese2024imbalance}.

Επιπλέον, η διατήρηση της μεγαλύτερης συνεκτικής συνιστώσας
(\en{KeepLargestConnectedComponent}) λειτουργεί ως μορφολογικός περιορισμός
που μειώνει σποραδικά \en{false positives}, ιδιαίτερα σε μοντέλα με τάση
υπερ-τμηματοποίησης. Η μετα-επεξεργασία υλοποιήθηκε με εργαλεία του
\en{MONAI} \cite{monai_docs,monaitransforms}.

\paragraph{Προτεινόμενος πίνακας.}
Στον Πίνακα~\ref{tab:thr_postproc} συνοψίζεται η επίδραση
(α) του βέλτιστου κατωφλίου και (β) της μετα-επεξεργασίας.

\begin{table}[h]
\centering
\caption{Επίδραση κατωφλίου και μετα-επεξεργασίας στο \en{validation set}.}
\label{tab:thr_postproc}
\begin{tabular}{lccc}
\hline
\textbf{Μοντέλο} &
\en{\textbf{Metric @} $t{=}0.5$} &
\en{\textbf{Metric @} $t^\star$} &
\en{\textbf{Metric + LCC}} \\
\hline
\en{U-Net}            &  &  &  \\
\en{Attention U-Net}  &  &  &  \\
\en{DynUNet}          &  &  &  \\
\en{UNETR}            &  &  &  \\
\en{SwinUNETR}        &  &  &  \\
\en{SegResNet}        &  &  &  \\
\en{SegMamba}         &  &  &  \\
\hline
\end{tabular}
\end{table}

\section{Ποιοτική αξιολόγηση και \en{error analysis}}
\label{sec:disc_qualitative}

Η ποιοτική αξιολόγηση είναι κρίσιμη, επειδή μια υψηλή μέση τιμή σε
\en{overlap-based} μετρικές δεν εγγυάται πάντα οπτικά ικανοποιητικό
περίγραμμα (π.\,χ. «φουσκωμένες» προβλέψεις ή απώλεια λεπτών ορίων).
Η βιβλιογραφία προτείνει συμπληρωματική ποιοτική τεκμηρίωση, ειδικά σε
κλινικά ευαίσθητες εφαρμογές \cite{litjens2017survey}.

\paragraph{Τυπικά σφάλματα που αξίζει να σχολιάσεις.}
\begin{itemize}
  \item \textbf{Υπερ-τμηματοποίηση:} πρόβλεψη περιοχών εκτός πλακούντα,
        συνήθως σε ιστούς με παρόμοια ένταση.
  \item \textbf{Υπο-τμηματοποίηση:} απώλεια λεπτών/περιφερειακών τμημάτων
        ή ασυνέχειες στο περίγραμμα.
  \item \textbf{Ασυνέπειες κατά μήκος του άξονα $z$:} το \en{3D} μοντέλο
        δίνει γενικά καλύτερη συνοχή από \en{2D}, όμως μπορεί να εμφανιστούν
        τοπικά «σπασίματα» σε δύσκολες φέτες.
\end{itemize}

\paragraph{Προτεινόμενα σχήματα.}
Δείξε 4--6 αντιπροσωπευτικά \en{cases}:
2 «εύκολα», 2 «μέτρια», 2 «δύσκολα», με \en{GT} έναντι \en{prediction},
και (προαιρετικά) \en{error map}.
Αν αποθηκεύεις \en{per-slice} μετρικές, είναι χρήσιμο να φανεί πού «πέφτει»
η απόδοση μέσα στον όγκο.

Για την ερμηνεία των σφαλμάτων είναι χρήσιμη και η σύγκριση με
προηγούμενες εργασίες τμηματοποίησης πλακούντα σε \en{MRI}, οι οποίες
αναφέρουν παρόμοιες δυσκολίες λόγω κίνησης, ανομοιογένειας εντάσεων και
παρόμοιων ιστικών αντιθέσεων \cite{alan._2016,Wang2016SlicSeg,
shahedi2021placenta,shahedi2022automatic,liu2023evaluation}.

\section{Υπολογιστικό κόστος και πρακτικοί συμβιβασμοί}
\label{sec:disc_cost}

Πέρα από την ακρίβεια, στην πράξη έχει σημασία:
(α) ο αριθμός παραμέτρων,
(β) η μνήμη κατά την εκπαίδευση (\en{VRAM}),
και (γ) ο χρόνος ανά \en{epoch} και ανά \en{inference} σε πλήρη \en{3D} όγκο.

Τα \en{Transformer-based} μοντέλα (π.\,χ. \en{UNETR}
\cite{hatamizadeh2022unetr} και \en{SwinUNETR} \cite{hatamizadeh2022swinunetr})
συχνά απαιτούν περισσότερους πόρους, ενώ \en{CNN}-βασισμένες
\en{U-shaped} αρχιτεκτονικές (π.\,χ. \en{U-Net} \cite{ronneberger2015unet},
\en{Attention U-Net} \cite{oktay2018attentionunet},
\en{nnU-Net/DynUNet}-μορφές \cite{isensee2021nnunet},
\en{SegResNet} \cite{myronenko2018segresnet}) μπορεί να είναι πιο «οικονομικές»
με ανταγωνιστική επίδοση, ειδικά όταν το πρόβλημα ευνοεί ισχυρό τοπικό
\en{inductive bias}.

Αντίστοιχα, τα \en{State Space}-βασισμένα μοντέλα (π.\,χ. \en{SegMamba}
\cite{xing2024segmamba} που βασίζεται σε \en{Mamba} \cite{gu2023mamba})
στοχεύουν σε αποδοτική μοντελοποίηση μακρινών εξαρτήσεων, όμως στην πράξη
η συνολική απόδοση και το κόστος εξαρτώνται από την υλοποίηση και τις
ρυθμίσεις εκπαίδευσης.

\begin{table}[h]
\centering
\caption{Ενδεικτικός πίνακας κόστους (συμπλήρωσε από τα \en{logs}).}
\label{tab:cost}
\begin{tabular}{lccc}
\hline
\textbf{Μοντέλο} &
\textbf{\# Παράμετροι} &
\en{\textbf{VRAM (GB)}} &
\en{\textbf{sec/epoch}} \\
\hline
\en{U-Net}            &  &  &  \\
\en{Attention U-Net}  &  &  &  \\
\en{DynUNet}          &  &  &  \\
\en{UNETR}            &  &  &  \\
\en{SwinUNETR}        &  &  &  \\
\en{SegResNet}        &  &  &  \\
\en{SegMamba}         &  &  &  \\
\hline
\end{tabular}
\end{table}

\section{Σύγκριση με σχετικές εργασίες και περιορισμοί}
\label{sec:disc_lit_limits}

Για βιβλιογραφική τοποθέτηση, μπορείς να συγκρίνεις το επίπεδο επίδοσης
(ποσοτικά και ποιοτικά) με προηγούμενες προσεγγίσεις τμηματοποίησης
πλακούντα σε \en{MRI}, όπως \cite{shahedi2021placenta,shahedi2022automatic,
liu2023evaluation} και πιο παλαιότερες/εναλλακτικές μεθοδολογίες
\cite{Wang2016SlicSeg,alan._2016}.
Παρότι οι άμεσες συγκρίσεις επηρεάζονται από διαφορετικά \en{datasets},
\en{protocols} και μετρικές, η συζήτηση βοηθά να αποσαφηνιστεί αν οι τάσεις
απόδοσης που παρατηρούνται εδώ συμφωνούν με τη διεθνή βιβλιογραφία.

\paragraph{Περιορισμοί που αξίζει να δηλώσεις καθαρά.}
\begin{itemize}
  \item Μέγεθος συνόλου δεδομένων και πιθανή ετερογένεια πρωτοκόλλων.
  \item Δυαδική μάσκα (έλλειψη υπο-δομών/κλάσεων) και συνέπειες στη μάθηση.
  \item Αξιολόγηση σε ένα \en{split} (αν δεν εφαρμόστηκε \en{k-fold}).
  \item Περιορισμός στις μετρικές (π.\,χ. απουσία επιφανειακών αποστάσεων
        όπως \en{HD95}), κάτι που συχνά προτείνεται για πληρέστερη αξιολόγηση
        \cite{litjens2017survey}.
  \item Επιπτώσεις ανισορροπίας κλάσεων και επιλογών δειγματοληψίας
        \en{patches} \cite{sudre2017gdl,morgese2024imbalance}.
\end{itemize}

\section{Σύνοψη}
\label{sec:disc_summary}

Συνοψίζοντας, το ενιαίο πειραματικό πλαίσιο επιτρέπει αξιόπιστη σύγκριση
μεταξύ κλασικών \en{CNN} αρχιτεκτονικών και νεότερων μοντέλων
(\en{Transformer}/\en{State Space}).
Τα τελικά συμπεράσματα και οι προτάσεις για μελλοντική επέκταση
παρουσιάζονται στο επόμενο κεφάλαιο.
