\chapter{Ανάλυση Αποτελεσμάτων και Συζήτηση}
\label{ch:discussion}

Στο κεφάλαιο αυτό αναλύονται και ερμηνεύονται τα αποτελέσματα του
Κεφαλαίου~\ref{ch:experiments}, με στόχο να αποτυπωθούν:
(α) οι κύριες τάσεις απόδοσης ανά αρχιτεκτονική,
(β) η σταθερότητα σύγκλισης και η ευαισθησία σε υπερπαραμέτρους,
(γ) τα συνηθέστερα σφάλματα τμηματοποίησης και οι πιθανές αιτίες τους,
και (δ) οι πρακτικοί συμβιβασμοί κόστους (χρόνος/μνήμη) έναντι ακρίβειας.

Η συζήτηση βασίζεται στις καταγεγραμμένες μετρικές και στα \en{logs} των
\en{runs}, στις καμπύλες \en{train/val loss}, καθώς και σε ποιοτική
επιθεώρηση προβλέψεων σε αντιπροσωπευτικά \en{cases}.
Για γενικό πλαίσιο αξιολόγησης \en{deep learning} στην ιατρική απεικόνιση
και πρακτικές σύγκρισης μοντέλων, λαμβάνονται υπόψη οι κατευθύνσεις της
βιβλιογραφίας \cite{litjens2017survey}.

\section{Συνοπτική κατάταξη μοντέλων και κύρια ευρήματα}
\label{sec:disc_ranking}

Ξεκινώντας από τον Πίνακα~\ref{tab:main_results}, συγκρίνουμε τις
αρχιτεκτονικές ως προς τη μέση επίδοση στο \en{validation set}.
Η κύρια μετρική αναφοράς είναι η επικάλυψη τύπου \en{Dice}-based (και
συμπληρωματικά \en{IoU}-τύπου), καθώς είναι ιδιαίτερα κατάλληλες σε
προβλήματα με αραιό \en{foreground} και έντονη ανισορροπία κλάσεων.
Η βιβλιογραφία υπογραμμίζει ότι σε τέτοιες ρυθμίσεις απαιτείται προσοχή
στην ερμηνεία των μετρικών και στην αναφορά αποτυχιών ανά περίπτωση
(\en{per-case failures}) \cite{litjens2017survey,morgese2024imbalance}.

Ειδικά σε \en{severely imbalanced} σενάρια (όπου ο \en{background} κυριαρχεί),
η σύγκλιση και η συμπεριφορά των \en{false positives/false negatives}
μπορούν να επηρεαστούν σημαντικά από τη στρατηγική δειγματοληψίας
\en{patches} και την επιλογή \en{loss}.
Στο πλαίσιο αυτό, απώλειες και μετρικές βασισμένες σε \en{Dice} έχουν
αναδειχθεί ως πρακτικές επιλογές για μη ισορροπημένες τμηματοποιήσεις
\cite{sudre2017gdl}.

\paragraph{Τι να γράψεις εδώ (με 2--3 παραγράφους).}
\begin{itemize}
  \item Ποιο μοντέλο έχει την καλύτερη μέση επίδοση και αν αυτό
        επιβεβαιώνεται και στη συμπληρωματική μετρική.
  \item Αν υπάρχουν «κοντινά» μοντέλα, σχολίασε με βάση τη σταθερότητα
        (π.\,χ. διακύμανση ανά \en{case}, ευαισθησία στο κατώφλι).
  \item Αν κάποιο μοντέλο έχει καλή μέση τιμή αλλά εμφανίζει αποτυχίες σε
        λίγες περιπτώσεις, ανέφερέ το ρητά (θα τεκμηριωθεί στην ενότητα
        ποιοτικής ανάλυσης).
\end{itemize}

\section{Σταθερότητα εκπαίδευσης και σύγκλιση}
\label{sec:disc_convergence}

Η συμπεριφορά σύγκλισης αποτιμάται από:
(α) τις καμπύλες \en{train/val loss},
(β) την εξέλιξη της επίδοσης στο \en{validation},
και (γ) την απόσταση μεταξύ \en{train} και \en{val} επίδοσης ως ένδειξη
\en{overfitting}.

Στο πειραματικό πλαίσιο χρησιμοποιήθηκε \en{AdamW} \cite{loshchilov2019adamw},
ενώ ο ρυθμός μάθησης μεταβλήθηκε με \en{CyclicLR} (υλοποίηση \en{PyTorch})
\cite{lr_schedulers}. Για την υλοποίηση των πειραμάτων και τη διατήρηση
κοινού \en{pipeline} μετασχηματισμών/αξιολόγησης αξιοποιήθηκε
\en{MONAI} \cite{cardoso2022monai,monai_docs,monai_github}.

\paragraph{Προτεινόμενα σχήματα.}
\begin{itemize}
  \item \textbf{Σχήμα 6.1:} \en{train/val loss} ανά \en{epoch}
        (ένα γράφημα ανά μοντέλο ή ομαδοποίηση 2--3 μοντέλων).
  \item \textbf{Σχήμα 6.2:} επίδοση στο \en{validation} ανά \en{epoch}.
  \item \textbf{Σχήμα 6.3:} \en{learning rate} ανά \en{epoch/step}
        (ώστε να τεκμηριώνεται ο \en{cyclical scheduler}).
\end{itemize}

Στην πράξη, τα μοντέλα μπορεί να διαφοροποιούνται ως προς:
(α) την ταχύτητα σταθεροποίησης, (β) την ευαισθησία σε υπερπαραμέτρους
(π.\,χ. \en{feature size}, \en{window size}), και (γ) την τάση
\en{overfitting} όταν το \en{capacity} είναι υψηλό σε σχέση με το διαθέσιμο
σύνολο δεδομένων.

\section{Επίδραση κατωφλίου και μετα-επεξεργασίας}
\label{sec:disc_threshold}

Η δυαδικοποίηση της εξόδου (\en{sigmoid}) απαιτεί επιλογή κατωφλίου $t$.
Παρότι το $t=0.5$ αποτελεί τυπική αρχική τιμή, στο παρόν πλαίσιο
εφαρμόστηκε περιοδική αναζήτηση σε πλέγμα τιμών (\en{threshold sweep}) και
υιοθέτηση του βέλτιστου ως προς την επίδοση στο \en{validation}.
Η διαδικασία αυτή είναι ιδιαίτερα χρήσιμη όταν η ανισορροπία κλάσεων
οδηγεί σε ασύμμετρη «ποινή» μεταξύ \en{false positives} και
\en{false negatives} \cite{morgese2024imbalance}.

Επιπλέον, η διατήρηση της μεγαλύτερης συνεκτικής συνιστώσας
(\en{KeepLargestConnectedComponent}) λειτουργεί ως μορφολογικός περιορισμός
που μειώνει σποραδικά \en{false positives}, ιδιαίτερα σε μοντέλα με τάση
υπερ-τμηματοποίησης. Η μετα-επεξεργασία υλοποιήθηκε με εργαλεία του
\en{MONAI} \cite{monai_docs,monaitransforms}.

\paragraph{Προτεινόμενος πίνακας.}
Στον Πίνακα~\ref{tab:thr_postproc} συνοψίζεται η επίδραση
(α) του βέλτιστου κατωφλίου και (β) της μετα-επεξεργασίας.

\begin{table}[h]
\centering
\caption{Επίδραση κατωφλίου και μετα-επεξεργασίας στο \en{validation set}.}
\label{tab:thr_postproc}
\begin{tabular}{lccc}
\hline
\textbf{Μοντέλο} &
\en{\textbf{Metric @} $t{=}0.5$} &
\en{\textbf{Metric @} $t^\star$} &
\en{\textbf{Metric + LCC}} \\
\hline
\en{U-Net}            &  &  &  \\
\en{Attention U-Net}  &  &  &  \\
\en{DynUNet}          &  &  &  \\
\en{UNETR}            &  &  &  \\
\en{SwinUNETR}        &  &  &  \\
\en{SegResNet}        &  &  &  \\
\en{SegMamba}         &  &  &  \\
\hline
\end{tabular}
\end{table}

\section{Ποιοτική αξιολόγηση και \en{error analysis}}
\label{sec:disc_qualitative}

Η ποιοτική αξιολόγηση είναι κρίσιμη, επειδή μια υψηλή μέση τιμή σε
\en{overlap-based} μετρικές δεν εγγυάται πάντα οπτικά ικανοποιητικό
περίγραμμα (π.\,χ. «φουσκωμένες» προβλέψεις ή απώλεια λεπτών ορίων).
Η βιβλιογραφία προτείνει συμπληρωματική ποιοτική τεκμηρίωση, ειδικά σε
κλινικά ευαίσθητες εφαρμογές \cite{litjens2017survey}.

\paragraph{Τυπικά σφάλματα που αξίζει να σχολιάσεις.}
\begin{itemize}
  \item \textbf{Υπερ-τμηματοποίηση:} πρόβλεψη περιοχών εκτός πλακούντα,
        συνήθως σε ιστούς με παρόμοια ένταση.
  \item \textbf{Υπο-τμηματοποίηση:} απώλεια λεπτών/περιφερειακών τμημάτων
        ή ασυνέχειες στο περίγραμμα.
  \item \textbf{Ασυνέπειες κατά μήκος του άξονα $z$:} το \en{3D} μοντέλο
        δίνει γενικά καλύτερη συνοχή από \en{2D}, όμως μπορεί να εμφανιστούν
        τοπικά «σπασίματα» σε δύσκολες φέτες.
\end{itemize}

\paragraph{Προτεινόμενα σχήματα.}
Δείξε 4--6 αντιπροσωπευτικά \en{cases}:
2 «εύκολα», 2 «μέτρια», 2 «δύσκολα», με \en{GT} έναντι \en{prediction},
και (προαιρετικά) \en{error map}.
Αν αποθηκεύεις \en{per-slice} μετρικές, είναι χρήσιμο να φανεί πού «πέφτει»
η απόδοση μέσα στον όγκο.

Για την ερμηνεία των σφαλμάτων είναι χρήσιμη και η σύγκριση με
προηγούμενες εργασίες τμηματοποίησης πλακούντα σε \en{MRI}, οι οποίες
αναφέρουν παρόμοιες δυσκολίες λόγω κίνησης, ανομοιογένειας εντάσεων και
παρόμοιων ιστικών αντιθέσεων \cite{alan._2016,Wang2016SlicSeg,
shahedi2021placenta,shahedi2022automatic,liu2023evaluation}.

\section{Υπολογιστικό κόστος και πρακτικοί συμβιβασμοί}
\label{sec:disc_cost}

Πέρα από την ακρίβεια, στην πράξη έχει σημασία:
(α) ο αριθμός παραμέτρων,
(β) η μνήμη κατά την εκπαίδευση (\en{VRAM}),
και (γ) ο χρόνος ανά \en{epoch} και ανά \en{inference} σε πλήρη \en{3D} όγκο.

Τα \en{Transformer-based} μοντέλα (π.\,χ. \en{UNETR}
\cite{hatamizadeh2022unetr} και \en{SwinUNETR} \cite{hatamizadeh2022swinunetr})
συχνά απαιτούν περισσότερους πόρους, ενώ \en{CNN}-βασισμένες
\en{U-shaped} αρχιτεκτονικές (π.\,χ. \en{U-Net} \cite{ronneberger2015unet},
\en{Attention U-Net} \cite{oktay2018attentionunet},
\en{nnU-Net/DynUNet}-μορφές \cite{isensee2021nnunet},
\en{SegResNet} \cite{myronenko2018segresnet}) μπορεί να είναι πιο «οικονομικές»
με ανταγωνιστική επίδοση, ειδικά όταν το πρόβλημα ευνοεί ισχυρό τοπικό
\en{inductive bias}.

Αντίστοιχα, τα \en{State Space}-βασισμένα μοντέλα (π.\,χ. \en{SegMamba}
\cite{xing2024segmamba} που βασίζεται σε \en{Mamba} \cite{gu2023mamba})
στοχεύουν σε αποδοτική μοντελοποίηση μακρινών εξαρτήσεων, όμως στην πράξη
η συνολική απόδοση και το κόστος εξαρτώνται από την υλοποίηση και τις
ρυθμίσεις εκπαίδευσης.

\begin{table}[h]
\centering
\caption{Ενδεικτικός πίνακας κόστους (συμπλήρωσε από τα \en{logs}).}
\label{tab:cost}
\begin{tabular}{lccc}
\hline
\textbf{Μοντέλο} &
\textbf{\# Παράμετροι} &
\en{\textbf{VRAM (GB)}} &
\en{\textbf{sec/epoch}} \\
\hline
\en{U-Net}            &  &  &  \\
\en{Attention U-Net}  &  &  &  \\
\en{DynUNet}          &  &  &  \\
\en{UNETR}            &  &  &  \\
\en{SwinUNETR}        &  &  &  \\
\en{SegResNet}        &  &  &  \\
\en{SegMamba}         &  &  &  \\
\hline
\end{tabular}
\end{table}

\section{Σύγκριση με σχετικές εργασίες και περιορισμοί}
\label{sec:disc_lit_limits}

Για βιβλιογραφική τοποθέτηση, μπορείς να συγκρίνεις το επίπεδο επίδοσης
(ποσοτικά και ποιοτικά) με προηγούμενες προσεγγίσεις τμηματοποίησης
πλακούντα σε \en{MRI}, όπως \cite{shahedi2021placenta,shahedi2022automatic,
liu2023evaluation} και πιο παλαιότερες/εναλλακτικές μεθοδολογίες
\cite{Wang2016SlicSeg,alan._2016}.
Παρότι οι άμεσες συγκρίσεις επηρεάζονται από διαφορετικά \en{datasets},
\en{protocols} και μετρικές, η συζήτηση βοηθά να αποσαφηνιστεί αν οι τάσεις
απόδοσης που παρατηρούνται εδώ συμφωνούν με τη διεθνή βιβλιογραφία.

\paragraph{Περιορισμοί που αξίζει να δηλώσεις καθαρά.}
\begin{itemize}
  \item Μέγεθος συνόλου δεδομένων και πιθανή ετερογένεια πρωτοκόλλων.
  \item Δυαδική μάσκα (έλλειψη υπο-δομών/κλάσεων) και συνέπειες στη μάθηση.
  \item Αξιολόγηση σε ένα \en{split} (αν δεν εφαρμόστηκε \en{k-fold}).
  \item Περιορισμός στις μετρικές (π.\,χ. απουσία επιφανειακών αποστάσεων
        όπως \en{HD95}), κάτι που συχνά προτείνεται για πληρέστερη αξιολόγηση
        \cite{litjens2017survey}.
  \item Επιπτώσεις ανισορροπίας κλάσεων και επιλογών δειγματοληψίας
        \en{patches} \cite{sudre2017gdl,morgese2024imbalance}.
\end{itemize}

\section{Σύνοψη}
\label{sec:disc_summary}

Συνοψίζοντας, το ενιαίο πειραματικό πλαίσιο επιτρέπει αξιόπιστη σύγκριση
μεταξύ κλασικών \en{CNN} αρχιτεκτονικών και νεότερων μοντέλων
(\en{Transformer}/\en{State Space}).
Τα τελικά συμπεράσματα και οι προτάσεις για μελλοντική επέκταση
παρουσιάζονται στο επόμενο κεφάλαιο.
% ___________________________________________________________________

\section{Προεπεξεργασία}
\label{sec:exp_preproc}

Οι μετασχηματισμοί για την προεπεξεργασία επιλέχθηκαν απο την βιβλιοθήκη της 
\en{MONAI} \cite{monaitransforms} ώστε να διακρίνονται πιο πολύ οι περιοχές ενδιαφέροντος,
να διευκολύνουμε το μοντέλο να γενικεύεται πιο ιδανικά και να 
ελαττωθεί το υπολογιστικό κόστος σε ένα ιδιαίτερα αραιό \en{foreground} πρόβλημα. 

Το βασικό \en{pipeline} προεπεξεργασίας (κοινό για όλα τα μοντέλα) περιλαμβάνει:
\begin{itemize}
  \item \textbf{Επαναπροσανατολισμό} σε κοινό σύστημα αξόνων (\en{RAS}).
  \item \textbf{Αναδειγματοληψία} σε στοχευμένο \en{voxel spacing}
        $(2.0,2.0,2.0)$\,\en{mm}, για συγκρισιμότητα μεταξύ περιστατικών.
  \item \textbf{Κανονικοποίηση εντάσεων} με \en{percentiles} (2--99.9) και
        χαρτογράφηση σε $[0,1]$.
  \item \textbf{\en{Foreground cropping}} με \en{CropForegroundd} και
        \en{source\_key=label}, με περιθώριο $m=8$ \en{voxels}, ώστε να
        απομονώνεται περιοχή ενδιαφέροντος (περιορισμός \en{FOV}) και να
        μειώνεται η σπατάλη σε \en{background}.
  \item \textbf{\en{Padding}} σε σταθερό \en{roi\_size} $(96,96,64)$ και
        επιπλέον \textbf{\en{divisible padding}} (σε $(32,32,16)$) ώστε οι
        τελικές διαστάσεις να είναι συμβατές με τις απαιτήσεις των
        αρχιτεκτονικών.
\end{itemize}

Για επιτάχυνση της εκπαίδευσης, οι μετασχηματισμοί του βασικού \en{pipeline}
προϋπολογίζονται και αποθηκεύονται μέσω \en{PersistentDataset (cache)}, ενώ οι
στοχαστικοί μετασχηματισμοί επαύξησης εφαρμόζονται \en{on-the-fly}.

\section{Δειγματοληψία \en{patches} και επαύξηση δεδομένων}
\label{sec:exp_aug}

Λόγω του μεγάλου μεγέθους των \en{3D} όγκων και των περιορισμών μνήμης,
η εκπαίδευση πραγματοποιείται σε \en{patches} σταθερού μεγέθους
\en{$\texttt{roi\_size}$}.
Για την αντιμετώπιση της ισχυρής ανισορροπίας \en{background/foreground},
εφαρμόζεται \en{RandCropByPosNegLabeld} με ρύθμιση της αναλογίας
θετικών/αρνητικών \en{patches}.

Επιπλέον, χρησιμοποιείται \textbf{στρατηγική \en{curriculum}} στην αναλογία
\en{pos/neg} κατά τη διάρκεια της εκπαίδευσης:
\begin{itemize}
  \item \textbf{Στάδιο 1 (\en{epochs} 0--39):} \en{foreground-only} δειγματοληψία
        (\en{pos=1, neg=0}).
  \item \textbf{Στάδιο 2 (\en{epochs} 40--69):} \en{mixed} δειγματοληψία
        (\en{pos=3, neg=1}).
  \item \textbf{Στάδιο 3 (\en{epochs} 70+):} πιο ισορροπημένη δειγματοληψία
        (\en{pos=1, neg=1}).
\end{itemize}
Η σταδιακή εισαγωγή αρνητικών \en{patches} στοχεύει στη μείωση των
\en{false positives}, χωρίς να θυσιάζεται η ικανότητα του μοντέλου να “βλέπει”
αρκετό \en{foreground} στα πρώτα στάδια σύγκλισης.

Για βελτίωση της γενίκευσης εφαρμόζονται στοχαστικές επαυξήσεις όπως:
\begin{itemize}
  \item τυχαίες αναστροφές (\en{flip}) σε κάθε άξονα (\en{prob=0.5}),
  \item ήπιες περιστροφές (\en{range} $\approx 0.15$ \en{rad}) και
        αφινικοί μετασχηματισμοί (περιστροφή έως $\pi/6$ γύρω από $z$ και
        κλίμακα έως $\pm 0.2$),
  \item προσθήκη \en{Gaussian noise} (\en{std=0.02}) και
        \en{Gaussian smoothing} (τυπικές αποκλίσεις $\sigma\in[0.5,1.0]$),
\end{itemize}
ώστε να προσομοιώνεται μεταβλητότητα πρωτοκόλλων/θορύβου χωρίς αλλοίωση της
σημασιολογίας της μάσκας.

\section{Πρωτόκολλο εκπαίδευσης}
\label{sec:exp_training}

Η εκπαίδευση πραγματοποιείται για \en{$\texttt{epochs}=120$} με μικρό
\en{batch size} ($1$) λόγω μνήμης και χρήση \en{gradient accumulation}
(\en{\texttt{accum\_steps}=4}) ώστε να προσεγγίζεται μεγαλύτερο
αποτελεσματικό \en{batch}.

Οι κύριες επιλογές εκπαίδευσης είναι:
\begin{itemize}
  \item \textbf{Απώλεια:} \en{Dice + Cross-Entropy} μέσω \en{DiceCELoss},
        με \en{sigmoid} έξοδο και \en{include\_background=False}, ώστε να
        βελτιστοποιείται τόσο η επικάλυψη όσο και η σταθερότητα εκπαίδευσης.
        (Για ανάλυση, καταγράφονται επιπλέον τα επιμέρους \en{Dice-only} και
        \en{CE-only} σκέλη.)
  \item \textbf{Βελτιστοποιητής:} \en{AdamW} \cite{loshchilov2019adamw},
        με \en{weight decay} $2\cdot 10^{-5}$ και αρχικό
        \en{learning rate} \en{$\texttt{base\_lr}=2.5\cdot 10^{-5}$}.
  \item \textbf{\en{Scheduler:}} κυκλικός ρυθμός μάθησης
        \en{CyclicLR} \cite{smith2017cyclical} (\en{triangular2}) μεταξύ
        \en{$\texttt{base\_lr}$} και \en{$\texttt{max\_lr}=4\cdot 10^{-4}$}.
  \item \textbf{\en{Mixed precision}:} χρήση \en{AMP} για μείωση μνήμης και
        επιτάχυνση σε \en{GPU}.
  \item \textbf{\en{EMA}:} εκθετικός κινητός μέσος των βαρών
        (\en{decay=0.975}) για σταθερότερη αξιολόγηση.
  \item \textbf{Επιλογή καλύτερου μοντέλου / early stopping:} αποθήκευση
        του καλύτερου \en{checkpoint} με βάση το \en{Dice} στο
        \en{validation set} και διακοπή όταν δεν υπάρχει βελτίωση για
        \en{patience=30} αξιολογήσεις.
\end{itemize}

\section{Διαδικασία αξιολόγησης και μετρικές}
\label{sec:exp_metrics}

Η αξιολόγηση γίνεται σε επίπεδο \en{3D} όγκου.
Για την παραγωγή πρόβλεψης σε ολόκληρο τον όγκο χρησιμοποιείται
\en{sliding window inference} με \en{overlap=0.5} και \en{gaussian blending},
ώστε να είναι εφικτή η αξιολόγηση υπό περιορισμούς μνήμης.

Η κύρια μετρική αναφοράς είναι ο \textbf{συντελεστής \en{Dice}}:
\[
\mathrm{Dice}(P,G) = \frac{2|P\cap G|}{|P|+|G|},
\]
όπου $P$ η δυαδική πρόβλεψη και $G$ η δυαδική μάσκα αναφοράς.
Επιπλέον καταγράφεται το \textbf{\en{Intersection-over-Union (IoU/Jaccard)}}:
\[
\mathrm{IoU}(P,G) = \frac{|P\cap G|}{|P\cup G|}.
\]

Η δυαδικοποίηση πραγματοποιείται με κατώφλι (\en{threshold}).
Ως αρχική τιμή χρησιμοποιείται \en{$t=0.5$}, ενώ ανά τακτά διαστήματα
(\en{every 5 epochs}) εκτελείται \en{threshold sweep} σε πλέγμα τιμών
\en{$t\in[0.35,0.65]$} και επιλέγεται το βέλτιστο ως προς \en{Dice}.

Τέλος, εφαρμόζεται μετα-επεξεργασία με διατήρηση της μεγαλύτερης συνεκτικής
συνιστώσας (\en{KeepLargestConnectedComponent}), ώστε να μειωθούν
απομονωμένα \en{false positives} και να επιβληθεί ένας ρεαλιστικός
μορφολογικός περιορισμός (ενιαία κύρια περιοχή πλακούντα).

